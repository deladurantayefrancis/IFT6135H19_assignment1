{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from random import randint\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz')\n",
    "data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# training set with onehot encoding for labels\n",
    "train_data = data[0][0]\n",
    "train_labels = np.zeros((train_data.shape[0], 10))\n",
    "train_labels[np.arange(train_labels.shape[0]), data[0][1]] = 1\n",
    "\n",
    "# validation and test sets, normal encoding for labels\n",
    "valid_data, valid_labels = data[1]\n",
    "test_data, test_labels = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, hidden_dims=(1024,2048), n_hidden=2, mode='train', datapath=None, model_path=None,\n",
    "                batchsize=64, lr=0.0001, delta=.5, activation=\"ReLU\", initialization=\"normal\", epsilon=1e-8):\n",
    "        \n",
    "        self.dims = (784,) + hidden_dims + (10,)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.mode = mode\n",
    "        self.datapath = datapath\n",
    "        self.model_path = model_path\n",
    "        self.batchsize = batchsize\n",
    "        self.lr = lr\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # set activation function for hidden layers\n",
    "        if activation == \"ReLU\":\n",
    "            self.activation = self.ReLU\n",
    "            self.activation_prime = self.ReLU_prime\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_prime = self.sigmoid_prime\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = self.tanh\n",
    "            self.activation_prime = self.tanh_prime\n",
    "        else:\n",
    "            raise ValueError('Invalid activation function specified: ' + str(activation))\n",
    "        \n",
    "        # network parameters\n",
    "        self.W = []\n",
    "        self.b = [np.zeros(self.dims[i]) for i in range(1, len(self.dims))]\n",
    "        \n",
    "        # weight initialization\n",
    "        self.initialize_weights(n_hidden, self.dims, initialization)\n",
    "        \n",
    "        # keep count of the loss of each epoch\n",
    "        self.losses = []\n",
    "        \n",
    "        # keep count of current training epochs\n",
    "        self.epoch_cnt = 1\n",
    "    \n",
    "    ################################################\n",
    "    #  Weights initialization and parameter count  #\n",
    "    ################################################\n",
    "    \n",
    "    def initialize_weights(self, n_hidden, dims, option):\n",
    "        \n",
    "        if option == \"zero\":\n",
    "            for i in range(n_hidden + 1):\n",
    "                self.W.append( np.zeros((dims[i+1], dims[i])) )\n",
    "        \n",
    "        elif (option == \"normal\"):\n",
    "            for i in range(n_hidden + 1):\n",
    "                self.W.append( np.random.normal(0, 1, (dims[i+1], dims[i])) )\n",
    "        \n",
    "        elif (option == \"glorot\"):\n",
    "            for i in range(n_hidden + 1):\n",
    "                di = np.sqrt(6/(dims[i]+dims[i+1]))\n",
    "                self.W.append( np.random.uniform(-di, di, (dims[i+1], dims[i])) )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Invalid weight initialization specified: ' + str(option))\n",
    "        \n",
    "    def display_network(self, title=None):\n",
    "        \n",
    "        if title: print(title)\n",
    "        \n",
    "        for i in range(self.n_hidden + 1):\n",
    "            print(\"Layer\", i+1, end=\" - \")\n",
    "            print(\"W:\" + str(self.W[i].shape), end=\"\\t\")\n",
    "            print(\"b:\" + str(self.b[i].shape))\n",
    "        \n",
    "        weights_cnt = sum(map(np.size, self.W))\n",
    "        bias_cnt = sum(map(np.size, self.b))\n",
    "        print(\"Total number of parameters:\", weights_cnt + bias_cnt, \"\\n\")\n",
    "    \n",
    "    #################################################\n",
    "    #  Activation functions  and their derivatives  #\n",
    "    #################################################\n",
    "    \n",
    "    def ReLU(self, input):\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def ReLU_prime(self, input):\n",
    "        return np.where(input > 0, 1, 0)\n",
    "    \n",
    "    def sigmoid(self, input):\n",
    "        return 1 / (1 + np.exp(-input))\n",
    "    \n",
    "    def sigmoid_prime(self, input):\n",
    "        return self.sigmoid(input) * (1 - self.sigmoid(input))\n",
    "    \n",
    "    def tanh(self, input):\n",
    "        return 2 / (1 + np.exp(-2*input)) - 1\n",
    "    \n",
    "    def tanh_prime(self, input):\n",
    "        return 1 - self.tanh(input)**2\n",
    "    \n",
    "    def softmax(self, input):\n",
    "        rescaled = input - np.amax(input, axis=1)[:,np.newaxis] # for numerical stability\n",
    "        input_exp = np.exp(rescaled)\n",
    "        return input_exp / np.sum(input_exp, axis=1)[:,np.newaxis]\n",
    "    \n",
    "    ########################################\n",
    "    #  Forward, backward, loss and update  #\n",
    "    ########################################\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # cache stores z = Wx + b of every layer for backprop (z=x for first layer)\n",
    "        cache = [input]\n",
    "        \n",
    "        out = input\n",
    "        for i in range(self.n_hidden):\n",
    "            out = out @ self.W[i].T + self.b[i] # compute z = Wx + b\n",
    "            cache.append(out) # store z for backprop\n",
    "            out = self.activation(out) # compute a = activation(z)\n",
    "        \n",
    "        out = out @ self.W[-1].T + self.b[-1]\n",
    "        cache.append(out)\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out, cache\n",
    "    \n",
    "    def loss(self, prediction, labels):\n",
    "        return -np.sum(labels * np.log(prediction + self.epsilon))\n",
    "    \n",
    "    def backward(self, cache, labels):\n",
    "        \n",
    "        # cache contains z = Wx + b of every layer (z=x for first layer)\n",
    "        \n",
    "        grads_a = [0] * (self.n_hidden + 1)\n",
    "        \n",
    "        grads_a[-1] = self.softmax(cache[-1]) - labels\n",
    "        for i in range(self.n_hidden-1, -1, -1):\n",
    "            grads_a[i] = grads_a[i+1] @ self.W[i+1] * self.activation_prime(cache[i+1])\n",
    "        \n",
    "        grads_W = [0] * (self.n_hidden + 1)\n",
    "        grads_b = [0] * (self.n_hidden + 1)\n",
    "        \n",
    "        for i in range(self.n_hidden, -1, -1):\n",
    "            grads_W[i] = grads_a[i].T @ self.activation(cache[i]) / labels.shape[0]\n",
    "            grads_b[i] = np.mean(grads_a[i], axis=0)\n",
    "            \n",
    "        return (grads_W, grads_b)\n",
    "    \n",
    "    def update(self, grads, lr):\n",
    "        for i in range(self.n_hidden + 1):\n",
    "            self.W[i] -= lr * grads[0][i]\n",
    "            self.b[i] -= lr * grads[1][i]\n",
    "        \n",
    "    ##############################\n",
    "    #  Train and test functions  #\n",
    "    ##############################\n",
    "    \n",
    "    def train(self, train_data, train_labels, n_epochs, verbose=True):\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            if verbose:\n",
    "                print(datetime.now(), \"-\", \"Epoch\", self.epoch_cnt, end=\": \") \n",
    "            \n",
    "            # learning rate for this epoch\n",
    "            t = max(1, self.epoch_cnt)\n",
    "            lr = self.lr / t**self.delta\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            start, end = 0, self.batchsize\n",
    "            \n",
    "            while start < train_data.shape[0]:\n",
    "                \n",
    "                # forward pass and mini-batch loss\n",
    "                predictions, cache = self.forward(train_data[start:end])\n",
    "                epoch_loss += self.loss(predictions, train_labels[start:end])\n",
    "                \n",
    "                # backward pass and update\n",
    "                grads = self.backward(cache, train_labels[start:end])\n",
    "                self.update(grads, lr)\n",
    "                \n",
    "                # start/end for next mini-batch\n",
    "                start = end\n",
    "                end += self.batchsize\n",
    "            \n",
    "            mean_loss = epoch_loss / train_data.shape[0]\n",
    "            if verbose:\n",
    "                print(\"loss =\", mean_loss)\n",
    "            \n",
    "            self.losses.append(mean_loss)\n",
    "            self.epoch_cnt += 1\n",
    "        \n",
    "    def test(self, test_data, test_labels, verbose=True):\n",
    "        \n",
    "        predictions, cache = self.forward(test_data)\n",
    "        successes = (np.argmax(predictions, axis=1) == test_labels)\n",
    "        \n",
    "        success_rate = 100 * np.sum(successes) / test_data.shape[0]\n",
    "        \n",
    "        if verbose:\n",
    "            print(str(success_rate) + \"% success\")\n",
    "        \n",
    "        return success_rate\n",
    "    \n",
    "    ############################################\n",
    "    #  Finite difference computation function  #\n",
    "    ############################################\n",
    "    \n",
    "    def finite_diff(self, sample, label):\n",
    "        \n",
    "        #first layer weight\n",
    "        weight_save = np.copy(self.W[0])\n",
    "        \n",
    "        #choose five random value from set N\n",
    "        num_N = 5\n",
    "        P = np.min([10, hidden_dims[0]])\n",
    "        w_size = 784\n",
    "        N = []\n",
    "        K = [1, 5]\n",
    "        fi_grad = np.zeros((num_N, P, w_size))\n",
    "        for num_N in range(num_N):\n",
    "            i = randint(0,5)\n",
    "            k = K[randint(0,1)]\n",
    "            N.append(k * 10^i)\n",
    "        \n",
    "        #calculate finite difference for first 10 weights in first layer\n",
    "        for i in range(len(N)):\n",
    "            epsilon = 1 / N[i]\n",
    "            grad = np.zeros((P,w_size))\n",
    "            for p in range(P):\n",
    "                print(\"Calculate \", p, \"hiddent unit!!\") \n",
    "                #restore the original weight before going to next finite difference calculation\n",
    "                self.W[0] = np.copy(weight_save)\n",
    "                for z in range(w_size):\n",
    "                    w1 = np.copy(self.W[0])\n",
    "                    w2 = np.copy(self.W[0])\n",
    "\n",
    "                    w1[p][z] -= epsilon\n",
    "                    w2[p][z] += epsilon\n",
    "\n",
    "                    #theta(i) - epsilon\n",
    "                    self.W[0] = np.copy(w1)\n",
    "                    L1, dum = self.forward(sample)\n",
    "                    L1_loss = self.loss(L1, label)\n",
    "                    #theta(i) + epsilon\n",
    "                    self.W[0] = np.copy(w2)\n",
    "                    L2, dum = self.forward(sample)\n",
    "                    L2_loss = self.loss(L2, label)\n",
    "                    g = (L2_loss-L1_loss)/(2*epsilon)\n",
    "                    grad[p,z] = g\n",
    "                    \n",
    "                    \n",
    "            fi_grad[i,:] = grad\n",
    "            \n",
    "        #True gradient Calculation\n",
    "        prediction, cache = self.forward(sample)\n",
    "        loss = self.loss(prediction, label)\n",
    "        grads = self.backward(cache, label)\n",
    "        \n",
    "        #fi_grad(finite_difference)\n",
    "        \n",
    "        return fi_grad, grads[0][0][0:9,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average loss per training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = (512, 1024)\n",
    "n_hidden = 2\n",
    "mode = 'train'\n",
    "datapath = None\n",
    "model_path = None\n",
    "batchsize = 128\n",
    "lr = .1\n",
    "delta = .5\n",
    "activation = \"ReLU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average loss over initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOROT INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-15 17:24:41.189479 - Epoch 1: loss = 2.2204062127728594\n",
      "2019-02-15 17:24:49.362479 - Epoch 2: loss = 1.212136205620917\n",
      "2019-02-15 17:24:56.951699 - Epoch 3: loss = 0.799717992114126\n",
      "2019-02-15 17:25:04.106100 - Epoch 4: loss = 0.6460414074659874\n",
      "2019-02-15 17:25:11.401745 - Epoch 5: loss = 0.5670922200231331\n",
      "2019-02-15 17:25:18.497000 - Epoch 6: loss = 0.5188178730549611\n",
      "2019-02-15 17:25:25.699811 - Epoch 7: loss = 0.4858894499104902\n",
      "2019-02-15 17:25:32.982101 - Epoch 8: loss = 0.46184314314063246\n",
      "2019-02-15 17:25:40.067819 - Epoch 9: loss = 0.44348874866750937\n",
      "2019-02-15 17:25:47.250802 - Epoch 10: loss = 0.42902443754658415\n",
      "\n",
      "\n",
      "NORMAL INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-15 17:25:54.399189 - Epoch 1: loss = 3.2690244309052847\n",
      "2019-02-15 17:26:01.613016 - Epoch 2: loss = 1.3835291678030766\n",
      "2019-02-15 17:26:08.793060 - Epoch 3: loss = 1.0899458944594305\n",
      "2019-02-15 17:26:15.978996 - Epoch 4: loss = 0.9424582966604304\n",
      "2019-02-15 17:26:23.189504 - Epoch 5: loss = 0.8475948838442691\n",
      "2019-02-15 17:26:30.811270 - Epoch 6: loss = 0.7787008578868829\n",
      "2019-02-15 17:26:38.633237 - Epoch 7: loss = 0.7250389334987968\n",
      "2019-02-15 17:26:47.397697 - Epoch 8: loss = 0.681460172097487\n",
      "2019-02-15 17:26:55.874815 - Epoch 9: loss = 0.6451367876522008\n",
      "2019-02-15 17:27:04.307851 - Epoch 10: loss = 0.6142573952481173\n",
      "\n",
      "\n",
      "ZERO INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-15 17:27:13.253240 - Epoch 1: loss = 2.437228062993084\n",
      "2019-02-15 17:27:21.304071 - Epoch 2: loss = 2.3177181523946677\n",
      "2019-02-15 17:27:29.334193 - Epoch 3: loss = 2.3113188033329286\n",
      "2019-02-15 17:27:37.823177 - Epoch 4: loss = 2.3085113510909845\n",
      "2019-02-15 17:27:45.825822 - Epoch 5: loss = 2.306795969818714\n",
      "2019-02-15 17:27:53.533445 - Epoch 6: loss = 2.305560679874472\n",
      "2019-02-15 17:28:01.157171 - Epoch 7: loss = 2.3045748516583866\n",
      "2019-02-15 17:28:08.227845 - Epoch 8: loss = 2.303730077644934\n",
      "2019-02-15 17:28:15.291961 - Epoch 9: loss = 2.3029675264700336\n",
      "2019-02-15 17:28:22.481263 - Epoch 10: loss = 2.3022516652345937\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initializations = [\"glorot\", \"normal\", \"zero\"]\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "n_epochs = 10\n",
    "xrange = np.arange(n_epochs) + 1\n",
    "\n",
    "for init, c in zip(initializations, colors):\n",
    "    \n",
    "    np.random.seed(6135)\n",
    "    \n",
    "    neural_net = NN(hidden_dims, n_hidden, mode, datapath, model_path,\n",
    "                    batchsize, lr, delta, activation, initialization=init)\n",
    "    neural_net.display_network(init.upper() + \" INITIALIZATION:\")\n",
    "    \n",
    "    neural_net.train(train_data, train_labels, n_epochs)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    plt.plot(xrange, neural_net.losses, color=c, label=(init + \" initialization\"))\n",
    "\n",
    "plt.title(\"Average loss per training example over the first 10 epochs\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss per traning example\")\n",
    "plt.xticks(xrange)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search using glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed settings for building our networks\n",
    "n_hidden = 2\n",
    "mode = 'train'\n",
    "datapath = None\n",
    "model_path = None\n",
    "initialization = \"glorot\"\n",
    "\n",
    "# don't display loss nor valid success rate at the end of each epoch\n",
    "verbose = False\n",
    "\n",
    "# patience hyperparameter (number of epochs without progress before stopping)\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 95.75%\n",
      "Reached after 15 epochs and 0:02:25.243072 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 94.97%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 94.47%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 89.84%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 88.48%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 87.46%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 63.91%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 58.68%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 55.61%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 65.47%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 53.82%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 43.69%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 31.0%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 34.06%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 31.91%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 94.49%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.62%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 93.11%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 89.99%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 88.92%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 88.33%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 75.82%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 72.7%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 71.14%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.22%\n",
      "Reached after 15 epochs and 0:01:38.920869 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 95.42%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.01%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.68%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.55%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 88.78%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 73.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 67.67%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 64.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 84.53%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 80.29%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 77.65%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 52.55%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 42.42%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 94.22%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.25%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 92.84%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.38%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.58%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.13%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 81.06%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 78.85%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 77.45%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.54%\n",
      "Reached after 15 epochs and 0:01:33.780279 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 95.72%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.48%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.12%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.41%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.9%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 75.54%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 71.68%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 69.23%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 86.55%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 84.35%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 82.39%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 56.17%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 44.69%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.43%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 93.89%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.06%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 92.81%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.47%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.98%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.6%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 82.96%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 80.18%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 78.6%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.82%\n",
      "Reached after 15 epochs and 0:01:16.555770 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.23%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.72%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.87%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 90.47%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 79.89%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 75.3%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 72.66%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 87.32%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 85.21%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 83.52%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 53.33%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 42.83%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 14.81%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 14.91%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 14.75%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 95.3%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 94.46%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 94.01%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.31%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.99%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 84.46%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 82.13%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 80.5%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 97.9%\n",
      "Reached after 15 epochs and 0:03:19.185112 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.85%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.71%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.15%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 94.09%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 93.47%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 88.94%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 87.23%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 85.97%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 90.9%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 90.49%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 89.97%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 80.37%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 73.95%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 69.56%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 36.84%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 30.33%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 26.52%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.24%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.23%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.1%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.88%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 93.02%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.56%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 89.43%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 88.18%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 87.41%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best success rate: 98.07%\n",
      "Reached after 15 epochs and 0:02:49.263820 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.98%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.59%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 94.73%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 94.16%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.07%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 88.59%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 87.76%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 91.51%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 91.35%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.21%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 83.92%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 79.87%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 77.29%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 44.52%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 34.5%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 27.73%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.42%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.32%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.06%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.53%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 92.76%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.5%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 89.92%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.08%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 88.44%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.1%\n",
      "Reached after 13 epochs and 0:03:08.472713 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.91%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 95.32%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 94.76%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.7%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.79%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 88.8%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 91.63%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 91.58%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.42%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 85.55%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 82.45%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 80.39%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 48.4%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 36.32%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 28.77%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.53%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.48%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.23%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.35%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 92.81%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.56%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.12%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.54%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.29%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 98.09%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.1%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.08%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 96.3%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 95.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 95.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 91.2%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 90.31%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.83%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 92.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 92.13%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.91%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 86.1%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 83.11%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 80.88%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 46.29%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 35.46%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 30.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.62%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.49%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 94.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 93.92%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 93.6%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.51%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.92%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.52%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.23%\n",
      "Reached after 12 epochs and 0:13:13.874125 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.08%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.15%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.62%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.49%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 94.53%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 93.28%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.83%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.37%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.14%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.28%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 90.69%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 74.82%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 66.93%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 63.72%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.58%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.56%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.57%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.22%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.14%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 96.97%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 93.29%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.47%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.12%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.26%\n",
      "Reached after 10 epochs and 0:12:52.735666 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "Best success rate: 98.3%\n",
      "Reached after 10 epochs and 0:12:54.972299 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.26%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.89%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.86%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 95.09%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 94.08%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 93.55%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.14%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.75%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.47%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.26%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.02%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 81.1%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 76.07%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 72.53%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.79%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.78%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.68%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.45%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.09%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 96.93%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 93.01%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.47%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.21%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.32%\n",
      "Reached after 9 epochs and 0:15:06.377766 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 98.21%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.2%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 98.01%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 95.55%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 94.67%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 94.18%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.45%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.34%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.39%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.43%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.09%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 83.58%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 79.61%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 76.58%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.96%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.71%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.92%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.43%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.22%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.02%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 92.95%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.49%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.27%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.33%\n",
      "Reached after 15 epochs and 0:15:43.331946 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.29%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.27%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 98.1%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 98.02%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.95%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 95.16%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 94.79%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.68%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.33%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 96.07%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 92.16%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.8%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.46%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 84.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 80.36%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 77.61%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.34%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.2%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.56%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.26%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.1%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 94.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 93.5%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 93.13%\n"
     ]
    }
   ],
   "source": [
    "best_success_rate = 0\n",
    "max_number_of_epochs = 15\n",
    "\n",
    "# testing all combinations of a subset of hyperparameters\n",
    "for batchsize in [256, 32, 4]:\n",
    "    for hidden_dims in [(128, 4096), (256, 2048), (512, 1024), (1024, 128)]:\n",
    "        for activation in [\"ReLU\", \"sigmoid\", \"tanh\"]:\n",
    "            for lr in [.1, .01, .001]:\n",
    "                for delta in [.5, .75, .9]:\n",
    "                    \n",
    "                    start_time = datetime.now()\n",
    "                    \n",
    "                    params = {\n",
    "                        \"batchsize\": batchsize,\n",
    "                        \"hidden_dims\": hidden_dims,\n",
    "                        \"activation\": activation,\n",
    "                        \"lr\": lr,\n",
    "                        \"delta\": delta,\n",
    "                    }\n",
    "                    \n",
    "                    print(params)\n",
    "                    \n",
    "                    # instantiate the network\n",
    "                    np.random.seed(6135)\n",
    "                    neural_net = NN(hidden_dims, n_hidden, mode, datapath, model_path,\n",
    "                                    batchsize, lr, delta, activation, initialization)\n",
    "                    \n",
    "                    # reset success rate and patience for the new network\n",
    "                    current_success_rate = 0\n",
    "                    patience_timer = 0\n",
    "                    \n",
    "                    # train until 'max number of epochs' of no progress during 'patience' number of epochs \n",
    "                    while patience_timer < patience and neural_net.epoch_cnt < max_number_of_epochs:\n",
    "                        neural_net.train(train_data, train_labels, n_epochs=1, verbose=verbose)\n",
    "                        success_rate = neural_net.test(valid_data, valid_labels, verbose=verbose)\n",
    "                        if success_rate > current_success_rate:\n",
    "                            current_success_rate = success_rate\n",
    "                            patience_timer = 0\n",
    "                        else:\n",
    "                            patience_timer += 1\n",
    "                            \n",
    "                    # if current network is better on valid set, save as new best network\n",
    "                    if current_success_rate > best_success_rate:\n",
    "                        \n",
    "                        best_success_rate = current_success_rate\n",
    "                        best_epoch = neural_net.epoch_cnt - patience_timer\n",
    "                        best_params = params\n",
    "                        \n",
    "                        print(\"Best success rate:\", best_success_rate, end=\"%\\n\")\n",
    "                        print(\"Reached after\", best_epoch, \"epochs and\",\n",
    "                              datetime.now() - start_time, \"time\\n\")\n",
    "                        \n",
    "                    else:\n",
    "                        print(\"   Success rate:\", current_success_rate, end=\"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finite difference gradient for first 10 weights in second layer\n",
    "f_grad, t_grad = net_glorot.finite_diff(np.expand_dims(train_data[0],axis=0), np.expand_dims(train_labels[0],axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
