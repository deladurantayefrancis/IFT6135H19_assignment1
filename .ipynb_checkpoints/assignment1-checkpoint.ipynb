{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from random import randint\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz')\n",
    "data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# training set with onehot encoding for labels\n",
    "train_data = data[0][0]\n",
    "train_labels = np.zeros((train_data.shape[0], 10))\n",
    "train_labels[np.arange(train_labels.shape[0]), data[0][1]] = 1\n",
    "\n",
    "# validation and test sets, normal encoding for labels\n",
    "valid_data, valid_labels = data[1]\n",
    "test_data, test_labels = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, hidden_dims=(1024,2048), n_hidden=2, mode='train', datapath=None, model_path=None,\n",
    "                batchsize=64, lr=0.0001, delta=.5, activation=\"ReLU\", initialization=\"normal\", epsilon=1e-8):\n",
    "        \n",
    "        self.dims = (784,) + hidden_dims + (10,)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.mode = mode\n",
    "        self.datapath = datapath\n",
    "        self.model_path = model_path\n",
    "        self.batchsize = batchsize\n",
    "        self.lr = lr\n",
    "        self.delta = delta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # set activation function for hidden layers\n",
    "        if activation == \"ReLU\":\n",
    "            self.activation = self.ReLU\n",
    "            self.activation_prime = self.ReLU_prime\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_prime = self.sigmoid_prime\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = self.tanh\n",
    "            self.activation_prime = self.tanh_prime\n",
    "        else:\n",
    "            raise ValueError('Invalid activation function specified: ' + str(activation))\n",
    "        \n",
    "        # network parameters\n",
    "        self.W = []\n",
    "        self.b = [np.zeros(self.dims[i]) for i in range(1, len(self.dims))]\n",
    "        \n",
    "        # weight initialization\n",
    "        self.initialize_weights(n_hidden, self.dims, initialization)\n",
    "        \n",
    "        # keep count of the loss of each epoch\n",
    "        self.losses = []\n",
    "        \n",
    "        # keep count of current training epochs\n",
    "        self.epoch_cnt = 1\n",
    "    \n",
    "    ################################################\n",
    "    #  Weights initialization and parameter count  #\n",
    "    ################################################\n",
    "    \n",
    "    def initialize_weights(self, n_hidden, dims, option):\n",
    "        \n",
    "        if option == \"zero\":\n",
    "            for i in range(n_hidden + 1):\n",
    "                self.W.append( np.zeros((dims[i+1], dims[i])) )\n",
    "        \n",
    "        elif (option == \"normal\"):\n",
    "            for i in range(n_hidden + 1):\n",
    "                self.W.append( np.random.normal(0, 1, (dims[i+1], dims[i])) )\n",
    "        \n",
    "        elif (option == \"glorot\"):\n",
    "            for i in range(n_hidden + 1):\n",
    "                di = np.sqrt(6/(dims[i]+dims[i+1]))\n",
    "                self.W.append( np.random.uniform(-di, di, (dims[i+1], dims[i])) )\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Invalid weight initialization specified: ' + str(option))\n",
    "        \n",
    "    def display_network(self, title=None):\n",
    "        \n",
    "        if title: print(title)\n",
    "        \n",
    "        for i in range(self.n_hidden + 1):\n",
    "            print(\"Layer\", i+1, end=\" - \")\n",
    "            print(\"W:\" + str(self.W[i].shape), end=\"\\t\")\n",
    "            print(\"b:\" + str(self.b[i].shape))\n",
    "        \n",
    "        weights_cnt = sum(map(np.size, self.W))\n",
    "        bias_cnt = sum(map(np.size, self.b))\n",
    "        print(\"Total number of parameters:\", weights_cnt + bias_cnt, \"\\n\")\n",
    "    \n",
    "    #################################################\n",
    "    #  Activation functions  and their derivatives  #\n",
    "    #################################################\n",
    "    \n",
    "    def ReLU(self, input):\n",
    "        return np.maximum(0, input)\n",
    "    \n",
    "    def ReLU_prime(self, input):\n",
    "        return np.where(input > 0, 1, 0)\n",
    "    \n",
    "    def sigmoid(self, input):\n",
    "        return 1 / (1 + np.exp(-input))\n",
    "    \n",
    "    def sigmoid_prime(self, input):\n",
    "        return self.sigmoid(input) * (1 - self.sigmoid(input))\n",
    "    \n",
    "    def tanh(self, input):\n",
    "        return 2 / (1 + np.exp(-2*input)) - 1\n",
    "    \n",
    "    def tanh_prime(self, input):\n",
    "        return 1 - self.tanh(input)**2\n",
    "    \n",
    "    def softmax(self, input):\n",
    "        rescaled = input - np.amax(input, axis=1)[:,np.newaxis] # for numerical stability\n",
    "        input_exp = np.exp(rescaled)\n",
    "        return input_exp / np.sum(input_exp, axis=1)[:,np.newaxis]\n",
    "    \n",
    "    ########################################\n",
    "    #  Forward, backward, loss and update  #\n",
    "    ########################################\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # cache stores z = Wx + b of every layer for backprop (z=x for first layer)\n",
    "        cache = [input]\n",
    "        \n",
    "        out = input\n",
    "        for i in range(self.n_hidden):\n",
    "            out = out @ self.W[i].T + self.b[i] # compute z = Wx + b\n",
    "            cache.append(out) # store z for backprop\n",
    "            out = self.activation(out) # compute a = activation(z)\n",
    "        \n",
    "        out = out @ self.W[-1].T + self.b[-1]\n",
    "        cache.append(out)\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out, cache\n",
    "    \n",
    "    def loss(self, prediction, labels):\n",
    "        return -np.sum(labels * np.log(prediction + self.epsilon))\n",
    "    \n",
    "    def backward(self, cache, labels):\n",
    "        \n",
    "        # cache contains z = Wx + b of every layer (z=x for first layer)\n",
    "        \n",
    "        grads_a = [0] * (self.n_hidden + 1)\n",
    "        \n",
    "        grads_a[-1] = self.softmax(cache[-1]) - labels\n",
    "        for i in range(self.n_hidden-1, -1, -1):\n",
    "            grads_a[i] = grads_a[i+1] @ self.W[i+1] * self.activation_prime(cache[i+1])\n",
    "        \n",
    "        grads_W = [0] * (self.n_hidden + 1)\n",
    "        grads_b = [0] * (self.n_hidden + 1)\n",
    "        \n",
    "        for i in range(self.n_hidden, -1, -1):\n",
    "            grads_W[i] = grads_a[i].T @ self.activation(cache[i]) / labels.shape[0]\n",
    "            grads_b[i] = np.mean(grads_a[i], axis=0)\n",
    "            \n",
    "        return (grads_W, grads_b)\n",
    "    \n",
    "    def update(self, grads, lr):\n",
    "        for i in range(self.n_hidden + 1):\n",
    "            self.W[i] -= lr * grads[0][i]\n",
    "            self.b[i] -= lr * grads[1][i]\n",
    "        \n",
    "    ##############################\n",
    "    #  Train and test functions  #\n",
    "    ##############################\n",
    "    \n",
    "    def train(self, train_data, train_labels, n_epochs, verbose=True):\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            if verbose:\n",
    "                print(datetime.now(), \"-\", \"Epoch\", self.epoch_cnt, end=\": \") \n",
    "            \n",
    "            # learning rate for this epoch\n",
    "            t = max(1, self.epoch_cnt)\n",
    "            lr = self.lr / t**self.delta\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            start, end = 0, self.batchsize\n",
    "            \n",
    "            while start < train_data.shape[0]:\n",
    "                \n",
    "                # forward pass and mini-batch loss\n",
    "                predictions, cache = self.forward(train_data[start:end])\n",
    "                epoch_loss += self.loss(predictions, train_labels[start:end])\n",
    "                \n",
    "                # backward pass and update\n",
    "                grads = self.backward(cache, train_labels[start:end])\n",
    "                self.update(grads, lr)\n",
    "                \n",
    "                # start/end for next mini-batch\n",
    "                start = end\n",
    "                end += self.batchsize\n",
    "            \n",
    "            mean_loss = epoch_loss / train_data.shape[0]\n",
    "            if verbose:\n",
    "                print(\"loss =\", mean_loss)\n",
    "            \n",
    "            self.losses.append(mean_loss)\n",
    "            self.epoch_cnt += 1\n",
    "        \n",
    "    def test(self, test_data, test_labels, verbose=True):\n",
    "        \n",
    "        predictions, cache = self.forward(test_data)\n",
    "        successes = (np.argmax(predictions, axis=1) == test_labels)\n",
    "        \n",
    "        success_rate = 100 * np.sum(successes) / test_data.shape[0]\n",
    "        \n",
    "        if verbose:\n",
    "            print(str(success_rate) + \"% success\")\n",
    "        \n",
    "        return success_rate\n",
    "    \n",
    "    ############################################\n",
    "    #  Finite difference computation function  #\n",
    "    ############################################\n",
    "    \n",
    "    def finite_diff(self, sample, label):\n",
    "        random.seed(9001)\n",
    "        #first layer weight\n",
    "        weight_save = np.copy(self.W[1])\n",
    "        \n",
    "        #choose five random value from set N\n",
    "        num_N = 5\n",
    "        P = np.min([10, self.dims[2]])\n",
    "        w_size = self.dims[1]\n",
    "        N = []\n",
    "        K = [1, 5]\n",
    "        fi_grad = np.zeros((num_N, P, w_size))\n",
    "        for num_N in range(num_N):\n",
    "            i = random.randint(0,5)\n",
    "            k = K[random.randint(0,1)]\n",
    "            N.append(k * (10**i))\n",
    "        \n",
    "        N.sort()\n",
    "        print(N)\n",
    "        #calculate finite difference for first 10 weights in first layer\n",
    "        for i in range(len(N)):\n",
    "            epsilon = 1 / N[i]\n",
    "            print(\"Set Epsilon = \", epsilon)\n",
    "            grad = np.zeros((P,w_size))\n",
    "            for p in range(P):\n",
    "                print(\"Calculate \", p, \"hidden unit!!\") \n",
    "                #restore the original weight before going to next finite difference calculation\n",
    "                self.W[1] = np.copy(weight_save)\n",
    "                for z in range(w_size):\n",
    "                    w1 = np.copy(self.W[1])\n",
    "                    w2 = np.copy(self.W[1])\n",
    "\n",
    "                    w1[p][z] -= epsilon\n",
    "                    w2[p][z] += epsilon\n",
    "\n",
    "                    #theta(i) - epsilon\n",
    "                    self.W[1] = np.copy(w1)\n",
    "                    L1, dum = self.forward(sample)\n",
    "                    L1_loss = self.loss(L1, label)\n",
    "                    #theta(i) + epsilon\n",
    "                    self.W[1] = np.copy(w2)\n",
    "                    L2, dum = self.forward(sample)\n",
    "                    L2_loss = self.loss(L2, label)\n",
    "                    g = (L2_loss-L1_loss)/(2*epsilon)\n",
    "                    grad[p,z] = g\n",
    "                    \n",
    "                    \n",
    "            fi_grad[i,:] = grad\n",
    "            \n",
    "        self.W[1] = np.copy(weight_save)\n",
    "        #True gradient Calculation\n",
    "        prediction, cache = self.forward(sample)\n",
    "        loss = self.loss(prediction, label)\n",
    "        grads = self.backward(cache, label)\n",
    "        \n",
    "        #fi_grad(finite_difference)\n",
    "        \n",
    "        return N, fi_grad, grads[0][1][0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average loss per training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = (512, 1024)\n",
    "n_hidden = 2\n",
    "mode = 'train'\n",
    "datapath = None\n",
    "model_path = None\n",
    "batchsize = 64\n",
    "lr = .001\n",
    "delta = .5\n",
    "activation = \"ReLU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average loss over initialization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOROT INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-17 14:00:11.384010 - Epoch 1: loss = 2.0688190355192146\n",
      "2019-02-17 14:00:31.838006 - Epoch 2: loss = 1.631295016894271\n",
      "2019-02-17 14:00:50.333243 - Epoch 3: loss = 1.3180200304630643\n",
      "2019-02-17 14:01:08.770841 - Epoch 4: loss = 1.1058932510031625\n",
      "2019-02-17 14:01:25.939249 - Epoch 5: loss = 0.9641664759480044\n",
      "2019-02-17 14:01:43.702688 - Epoch 6: loss = 0.8660849745780653\n",
      "2019-02-17 14:02:02.941290 - Epoch 7: loss = 0.7949881578542642\n",
      "2019-02-17 14:02:25.526809 - Epoch 8: loss = 0.7412075592855083\n",
      "2019-02-17 14:02:45.591606 - Epoch 9: loss = 0.6990583295941705\n",
      "2019-02-17 14:03:06.737495 - Epoch 10: loss = 0.6650674928317611\n",
      "\n",
      "\n",
      "NORMAL INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-17 14:03:35.878002 - Epoch 1: loss = 3.2847279738326196\n",
      "2019-02-17 14:04:07.904411 - Epoch 2: loss = 1.7294045496984185\n",
      "2019-02-17 14:04:42.266750 - Epoch 3: loss = 1.4332135872248666\n",
      "2019-02-17 14:05:14.400034 - Epoch 4: loss = 1.2368752628935527\n",
      "2019-02-17 14:05:48.717207 - Epoch 5: loss = 1.0992140584966004\n",
      "2019-02-17 14:06:17.711947 - Epoch 6: loss = 1.014931215411298\n",
      "2019-02-17 14:06:38.853456 - Epoch 7: loss = 0.9353258637596782\n",
      "2019-02-17 14:07:02.658368 - Epoch 8: loss = 0.8776185233923555\n",
      "2019-02-17 14:07:33.448952 - Epoch 9: loss = 0.8263181451678329\n",
      "2019-02-17 14:08:00.001052 - Epoch 10: loss = 0.7616120105507926\n",
      "\n",
      "\n",
      "ZERO INITIALIZATION:\n",
      "Layer 1 - W:(512, 784)\tb:(512,)\n",
      "Layer 2 - W:(1024, 512)\tb:(1024,)\n",
      "Layer 3 - W:(10, 1024)\tb:(10,)\n",
      "Total number of parameters: 937482 \n",
      "\n",
      "2019-02-17 14:08:17.764640 - Epoch 1: loss = 2.302472499838375\n",
      "2019-02-17 14:08:32.299433 - Epoch 2: loss = 2.3022879426930762\n",
      "2019-02-17 14:08:47.769553 - Epoch 3: loss = 2.3021649534661206\n",
      "2019-02-17 14:09:03.269909 - Epoch 4: loss = 2.3020710603339527\n",
      "2019-02-17 14:09:20.622747 - Epoch 5: loss = 2.301994871284792\n",
      "2019-02-17 14:09:38.245497 - Epoch 6: loss = 2.301930794134618\n",
      "2019-02-17 14:09:55.143954 - Epoch 7: loss = 2.301875600049178\n",
      "2019-02-17 14:10:09.553279 - Epoch 8: loss = 2.3018272314905808\n",
      "2019-02-17 14:10:24.150344 - Epoch 9: loss = 2.301784286355161\n",
      "2019-02-17 14:10:38.368376 - Epoch 10: loss = 2.301745761351721\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd4FdX2v9+VEGrohB5J6C0QIDRFmoJwFFAURUVFVL5Yfopey/Ver72L3WsDL1gQu4AaLEhRUJSAoSMd6QJSpSVh//7Yk+QQzkkmySkp632eec6UXdbMmZnP7La2GGNQFEVRlLyICLcBiqIoSvFABUNRFEVxhQqGoiiK4goVDEVRFMUVKhiKoiiKK1QwFEVRFFeoYIQAEZkjIteH246igohcKSLfBjpsSUREHhSR98JtR2EJ5HmISAUR+UJEDojIx6X9HskNEektIlsDlV6RFAznBbtPRMqF2xblVERkkog8Wpg0jDGTjTH9Ax1WKRoE+iXlg0uAOkBNY8ywwtwjbu5nEXlERJaJSLqIPOjj+BUisllE/haRqSJSoyC2FAeKnGCISBxwNmCAwUHKo0ww0i1pFOQ66bUtXYTp/24ErDHGpOcVMED2rQPuBr7ykX4b4A3gKqyIHQFeDUCeRRNjTJFagPuB+cBzwJde+7sBO4FIr30XAUud9Qjgn8B6YC/wEVDDORaHFaDrgD+AH5z9HztpHgB+ANp4pV0T+AI4CCwEHgXmeR1vCXwH/AX8DlyayznNAa73svM+YDPwJ/AOUNU5Vh54z7F/v5NvHefYSGADcAjYCFzpJ68HgU+AD52wi4H2XsfrA58Cu510bvUR9z3nvK/PkfZoIA04ARwGvnD2bwLuAZYCx4EyXv/FIWAlcJFXOiNzXEsDjAHWAvuA/wJSgLCRwLPAHufcbnHCl/FzrXK7FsnAs17bHwL/c9abALOc/2kPMBmo5hV2E3CXcz3+Bt7CvkxmONdjJlA9x705GtgO7AD+keM/eS/Hc/CTc38sAXrnct+1wt57+4EVwOBgPUte6VQCjgInnXvksHOdH3TSece5BiuAJDf/RY70H8Lef2lO2tf5uUdudu6RjYAAz2OftwPO/9IWP/dzLtfzPeDBHPseB9732m7ipFfZTxp+3xvAJOB15/ghYC7QyOv4mdh3wgHn90yvYzWAic49tA+Y6uzvDWwF/uGc/w7gWq94HuzzeQjYBtyZ6zUoyEs9mAtWzW8COjl/Zh2vY+uBfl7bHwP/dNbHAguAhkA5rOpPyXGTv+Pc0BWc/aOAyk74F4BUr7Q/cJaKQGtgS+ZN6aSxBbgW+3LsiH1xtPFzTnPIFoxRzjk2BqKBz4B3nWP/hxWpitiXXyegipPfQaCFE65eLnk96Fy3S4Ao4E7sQxOFfREswopyWceGDcB5OeJe6ISt4CP9ScCjOfZtAlKBWK9rOwz7EogALsO+OOs5x0Zy+gP+JVANOAP70hhQgLBjsDd/Q6A69sXsUzBcXIu62AesL3Clc6yyc6wp0A9738RgPzZeyHE9FmBFooGTzmKggxNnFvBAjntzivM/JzjndK7Xf/Kes94A+wL3OPb3c7ZjfJxfFPY++5dzfn2xL4XMeyigz1KOvHsDW33cl8cc2yOBJ4AFbv4LP/e4t4j6uke+w75EKwDnOelXw4pHK7LvxUnkuJ9zeTf5EoxpwD059h0GOvmIn+t7w7HlENDTue4vkv3OqYEVgqucuJc72zWd419hP2qqO/99L6//Ih142NnvwZaCMj9YdgBnO+vVgY65XoNAvOQDtQA9sC+sWs72auB2r+OPkv2VVxn7EmrkbK8CzvEKW89Jq4zXTd44l7yrOWGqOjd0Gs7D5ZV35p93GfBjjvhv4LwEfKQ9h2zB+B64yetYCy87R2G/Htv5uNH2Axfj4wH18TAt8NqOyLwpgK7AHznC3wtM9Ir7Qx7pT8K3YIzKI14qMMRZH8npD3gPr+2PyH555SfsLOD/vI6di3/ByPVaONtDsQ/4Hu88faR1IfBbjutxpdf2p8BrXtv/j+wvwMx7s6XX8aeBt7z+k0zBuAfn48Ir7DfANT5sOhtbiojw2jcF54VHcJ+l3vgWjJle262Bo27/Cx9p5SUYfb22+wJrsCWriBxpTaJwgvE9MCbHvm34KPmRx3vDseUDr2PRQAb2Q+wq4NcccX92zr0etkRX3c9/cRSvZwD7AdPNWf8D+6Faxc01KGptGNcA3xpj9jjb7zv78Noe6jSGDwUWG2M2O8caAZ+LyH4R2Y+96TOwX3mZbMlcEZFIEXlSRNaLyEHsQw5QC/vVWMY7fI71RkDXzLyc/K7EfpXmRX1sdVQmm5286gDvYl8AH4jIdhF5WkSijDF/Y2+2McAOEflKRFrmkkeWrcaYk9giaX3H7vo57P4Xfq5RPjklnohcLSKpXvm0xV5bf+z0Wj+CfVjyG7Y+/v+znLi5Fl9iPx5+N8bMy9wpIrVF5AMR2ebcO+9x+rnt8lo/6mM75/l527rZORdfNg/LYXMP7AsjJ/WBLc7/751uA2c9YM9SPsj5v5V32hjc/Bf5xfsZmAW8gq2+3CUib4pIlUKk7c1hbC2AN1WwJYWcuHlveNt9GFt1VZ/T3xuQ/X/GAn8ZY/b5sXGvObW9x/uZuRhb6tgsInNFpLufNIAi1OgtIhWAS4FeIrJTRHYCtwPtRaQ9gDFmJfYiDQSuwN70mWwBBhpjqnkt5Y0x27zCGK/1K4Ah2K/QqtgvJ7BF1t3YYlxDr/CxOfKamyOvaGPMjS5OdTv2xsnkDCevXcaYNGPMQ8aY1tj6yguAq51z/8YY0w/7clgNjM8ljyxbRSTCOY/tjt0bc9hd2Rjj8YpryB1/x7P2i0gjx75bsEXmasBy7LUNJjvw/5/lxM21eAz7sqwnIpd77X8Ce77tjDFVgBEU/ty8bT0D+3/5svndHDZXMsY86SPsdiDW+f+9090GAX+WcpLXPeTrvPL6L/LLKTYYY14yxnQC2gDNsW1MBbE1JyuA9pkbItIYW520xkdYN+8N72c3GlsVtZ3T3xuQ/X9uAWqISLX8Gm+MWWiMGQLUBqZiS+x+KTKCgS3WZ2CLqonO0gr4Eeel6fA+cCu2nu9jr/2vA485LytEJEZEhuSSX2VsA+1ebJvB45kHjDEZ2LaFB0WkovM1723Dl0BzEblKRKKcpbOItHJxnlOA20Uk3rkhHgc+NMaki0gfEUkQkUhsm0UakCEidURksIhUcmw+7Fwrf3QSkaHO19tYJ84C4FfgoIjc4/RljxSRtiLS2YXdmezC1jHnRiXsg7gbQESuxZYwgs1HwG0i0sB5eO7JJWyu10JEemLrmq92lpdFJPPrvDL2P9jv7LvLR/r55T/OvdbGyfdDH2HeAwaJyHmOveWdLqwNfYT9BVvNdLdzf/YGBmHb5TIJ1LOUk11ATRGp6jJ8IO5LvzjPZlcRicJek2NkPz953s/O9SuPfV+Wca57pHN4MvY/Odt5Ph8GPjPG+CphuHlveESkh4iUBR4BfjHGbMF2wmgutgtvGRG5DPuu/NIYswPboeJVEanupNvTxXUpK3YMS1VjTBr2nZPbe6VICcY12DrLP4wxOzMXbFHySsnuHjcFWy83y6vqCmwD0XTgWxE5hH1Bds0lv3ewX1jbsA2lC3IcvwVb8tiJrSqagn3x4twM/YHhWOXfCTyF/bLIi/856f2AbYw+hq3TBls0/QT7x63C9pJ4D/s//cPJ6y+gF7ZjgD+mYauwMhvJhjqllwzsSyPRyXsPMME5T7e8BbR2itRTfQVwvl6fxdax7sI25M7PRx4FZTzwLbYXzG/YhywdHw9BbtfCqa54B7jFGLPNqY56C5goIoLtqdMR21vlK+zHRWGZi22k/h4YZ4w5bSCa8+IYgq2u2Y39srwLH8+xMeYEtlv6QOfcXgWuNsas9goWqGcpZ96rnbQ3OPeJr+o17/CBuC9zowr23tiHfeb3AuOcY3nez07co9iG5n8761c5tq/AVhVPxrYNVMbPs+nyvfE+8AD2Oe+ErbLCGLMXW+PwD8f+u4ELvP63q7AfmKsdO8bmeVWy421yqlbHYEvLfsnsjqjkgYg8BdQ1xlyTZ+AwInZgUVNjTK5/fGlARAYCrxtjchbliwxixx1tBKKMi3EFSslFRCZhOwvcF25b/FGUShhFChFpKSLtxNIF29/783DbpfjHqc7wOEX2BtgvNf3PFCVAqGD4pzK2quFvbN34s9iqHqXoklldtA9bJbUK27dfUZQAoFVSiqIoiiu0hKEoiqK4otg5iqtVq5aJi4sLtxmKoijFikWLFu0xxsQUJo1iJxhxcXGkpKSE2wxFUZRihYjkHCmeb7RKSlEURXGFCoaiKIriChUMRVEUxRXFrg1DURRLWloaW7du5dixY+E2RSlClC9fnoYNGxIVFRXwtFUwFKWYsnXrVipXrkxcXBzWxZVS2jHGsHfvXrZu3Up8fHzA09cqKUUpphw7doyaNWuqWChZiAg1a9YMWqlTBUNRijEqFkpOgnlPlBrBWPHnCu745g6Opx8PtymKoijFklIjGJv2b+L5Bc/zw+Yfwm2KopR4Ro4cySeffBKQtCZNmsT27b4mIIT777+fmTNn5hp/+vTpPPmknZRw6tSprFy5Ml/xvc/l+uuvPyW+W3KeQ0HTCTelptG7T3wfykWWI3ltMv2a9Au3OYqieJGRkUFkZKTPY5MmTaJt27bUr3/6PEwPP/xwnmkPHjyYwYMHA1YwLrjgAlq3bu06vjcTJkzIV/hMcp5DQdMJN6WmhFExqiJ94vswY92McJuiKCWGRx55hJYtW9KvXz8uv/xyxo0bd1qY77//ng4dOpCQkMCoUaM4ftxWC8fFxfHwww/To0cPPv74Y1JTU+nWrRvt2rXjoosuYt++fXzyySekpKRw5ZVXkpiYyNGjR09J2/vrPy4ujgceeICOHTuSkJDA6tV2csFJkyZxyy238NNPPzF9+nTuuusuEhMTWb9+/SnxH374YTp37kzbtm0ZPXo0vjx59+7dm5SUFKZPn05iYiKJiYm0aNEiq0eSrzR8nUNmOgBTpkwhISGBtm3bcs892bMKR0dH8+9//5v27dvTrVs3du3aVdi/q9CUGsEAGNh0IL/v/Z31f60PtymKEljGjoXevQO7jM19ls+UlBQ+/fRTfvvtNz777DOfPt6OHTvGyJEj+fDDD1m2bBnp6em89tprWcfLly/PvHnzGD58OFdffTVPPfUUS5cuJSEhgYceeohLLrmEpKQkJk+eTGpqKhUqVMjVplq1arF48WJuvPHG08TrzDPPZPDgwTzzzDOkpqbSpEmTU47fcsstLFy4kOXLl3P06FG+/PJLv/kMHjyY1NRUUlNTad++PXfeeaffNHI7h+3bt3PPPfcwa9YsUlNTWbhwIVOn2pli//77b7p168aSJUvo2bMn48ePz/XcQ0GpEgxPMw+AljIUJQDMmzePIUOGUKFCBSpXrsygQYNOC/P7778THx9P8+bNAbjmmmv44YfsdsTLLrsMgAMHDrB//3569erlM5xbhg4dCkCnTp3YtGlTvuLOnj2brl27kpCQwKxZs1ixYkWecZ5++mkqVKjAzTffXKA0Fi5cSO/evYmJiaFMmTJceeWVWeddtmxZLrjgggKfTzAoNW0YAE1rNKVZjWYkr03mli63hNscRQkcL7wQ8izdTL6WV5hKlSoFyhwAypUrB0BkZCTp6e6nSD927Bg33XQTKSkpxMbG8uCDD+Y5luH777/n448/znrBFySN3K5PVFRUVhfZ/J5PsChVJQywpYzZm2ZzNO1o3oEVRfFLjx49+OKLLzh27BiHDx/mq6++Oi1My5Yt2bRpE+vWrQPg3XffzSpFeFO1alWqV6/Ojz/+eFq4ypUrc+jQoYDY7C+tzBd7rVq1OHz4cJ49vDZv3sxNN93ERx99lFXFlFsa/vLt2rUrc+fOZc+ePWRkZDBlyhSf16eoUKpKGGAF48VfXmTOpjkMbDYw3OYoSrGlc+fODB48mPbt29OoUSOSkpKoWrXqKWHKly/PxIkTGTZsGOnp6XTu3JkxY8b4TO/tt99mzJgxHDlyhMaNGzNx4kTANmyPGTOGChUq8PPPP+fZjpEbw4cP54YbbuCll1465YVerVo1brjhBhISEoiLi6Nz5865pjNp0iT27t3LRRddBED9+vVJTk72m0bOc8ikXr16PPHEE/Tp0wdjDB6PhyFDhhT4/IJNsZvTOykpyRRmAqVj6ceo+XRNRiWO4mXPywG0TFFCy6pVq2jVqlVYbTh8+DDR0dEcOXKEnj178uabb9KxY8ew2qT4vjdEZJExJqkw6Za6KqnyZcrTN74vyeuSXdXBKorin9GjR5OYmEjHjh25+OKLVSxKOKWuSgrA09TDl2u+ZM3eNbSo1SLc5ihKseX9998PtwlKCCl1JQwgq+1Cu9cqiqK4p1QKRly1OFrVakXy2uRwm6IoilJsKJWCAba31NzNczl84nC4TVEURSkWlGrBOJFxglkbZ4XbFEVRlGJBqRWMHmf0ILpsNDPWajuGohRXvJ34eePGffjrr7/OO++8AxTM/bh33h6Ph/379+fXfF544QWOHDmStV3QdEJFnr2kxI5NvxJobIx5WETOAOoaY34NunVBpGxkWc5tfG5W91qduUxRQkt6ejplygSno6Yb9+HeAwgL6348Oblg7aEvvPACI0aMoGLFioVKJ1S4KWG8CnQHLne2DwH/DZpFIcTT1MMfB/5g5e7iN5GJooSbTZs20apVK2644QbatGlD//79s9yP+3JVDvar/F//+he9evXixRdfZOTIkdx444306dOHxo0bM3fuXEaNGkWrVq0YOXJkVl433ngjSUlJtGnThgceeCBP27y//v25CX/wwQcZN25cnu7H3eQdFxfHnj17eP3117PcnsfHx9OnTx+/abz00kts376dPn36ZIXLTAfgueeeo23btrRt25YXHF9huV3zUOBG3rsaYzqKyG8Axph9IlI2yHaFhMzutclrk2lTu02YrVGUgjP267Gk7kwNaJqJdRN5YUDuTg3Xrl3LlClTGD9+PJdeeimffvopI0aM4Oqrr+bll1+mV69e3H///Tz00ENZL739+/czd+5cwLrM2LdvH7NmzWL69OkMGjSI+fPnM2HCBDp37kxqaiqJiYk89thj1KhRg4yMDM455xyWLl1Ku3btXJ1Hppvwxx57jLvvvpvx48dz3333ZR2/5JJLeOWVVxg3bhxJSacPhM5P3mPGjGHMmDGkpaXRt29f7rjjDr9p3HrrrTz33HPMnj2bWrVqnZLOokWLmDhxIr/88gvGGLp27UqvXr2oXr2632seCtyUMNJEJBIwACISA5zMK5KIlBeRX0VkiYisEJGHfIQpJyIfisg6EflFROLyaX+haFilIe3qtCN5XdEuBipKUSU+Pp7ExEQg2wV3Xq7KM12aZzJo0CBEhISEBOrUqUNCQgIRERG0adMmy6X3Rx99RMeOHenQoQMrVqzI1/SmhXUTXpC8b7vtNvr27Zvl8j2/acybN4+LLrqISpUqER0dzdChQ7McM/q65qHCTQnjJeBzoLaIPAZcAtyXexQAjgN9jTGHRSQKmCciM4wxC7zCXAfsM8Y0FZHhwFPAZb4SCxaeph7G/TyOg8cPUqVclVBmrSgBI6+SQLDIdCcO1gW3m+qRnC7NM9OIiIg4Jb2IiAjS09PZuHEj48aNY+HChVSvXp2RI0fm6Tbcm8K4CS9I3pMmTWLz5s288sorBU4jN7dFBbnmgSLPEoYxZjJwN/AEsAO40BjzsYt4xhiTOcghyllyXoUhwNvO+ifAORLi1ueBzQaSfjKdmRtynwheURR35OaqvCAcPHiQSpUqUbVqVXbt2sWMGYHv2ejP/Xh+8160aBHjxo3jvffeIyIiIs80/OXbs2dPpk6dypEjR/j777/5/PPPOfvsswt5loXHbwlDRGp4bf4JTPE+Zoz5K6/EnaqsRUBT4L/GmF9yBGkAbAEwxqSLyAGgJrAnRzqjgdEAZ5xxRl7Z5ovuDbtTtVxVktcmM7TV0ICmrSilFX+uygtC+/bt6dChA23atKFx48acddZZAbTU4s/9eH7zfuWVV/jrr7+yGrGTkpKYMGGC3zRGjx7NwIEDqVevHrNnz87a37FjR0aOHEmXLl0A2823Q4cOYZ91z697cxHZiC0R+PriN8aYxq4zEamGrdb6f8aY5V77VwDnGWO2OtvrgS7GmL3+0iqse3NfXPrxpczfMp+tt2/V7rVKsaEouDdXiiYhd29ujIk3xjR2fnMursXCSWs/MAcYkOPQViAWQETKAFWBPEsugcbTzMP2Q9tZumtpqLNWFEUpNrga6S0iQ0XkORF5VkQudBknxilZICIVgHOB1TmCTQeucdYvAWaZMExSMaCp1TF1RqgoiuKfPAVDRF4FxgDLgOXAGBFxM3CvHjBbRJYCC4HvjDFfisjDIjLYCfMWUFNE1gF3AP8syEkUlrrRdelYr6N2r1UURckFN91qewFtM7/8ReRtrHjkijFmKdDBx/77vdaPAcNcWxtEPE09PD7vcfYd3Uf1CtXDbY6iKEqRw02V1O+Ad9ekWKDEVfZ7mnk4aU7y3Ybvwm2KoihKkcSNYNQEVonIHBGZA6wEYkRkuohMD6p1IaRLgy7UqFBD2zEURVH84EYw7gcGAg84iwd4BHjWWUoEkRGRnNfkPGasm8FJk6fnE0VRQoC3C3J/pKSkcOuttwIwZ84cfvrpp3zFz3RCCHD//fczc2b+B/FOnTr1FHcfBU2nqJNnG4YxZi6AiFTxDu9m4F5xw9PMw5TlU1i8YzFJ9QvVXVlRlFzIyMggMjIyz3DeLsj9kZSUlOU0cM6cOURHR3PmmWe6ju/Nww8/nK/wmUydOpULLriA1q1bFyqdoo6bXlKjRWQXtt0iBTtyO7Aj54oI5zU5D0F0UiVFcYE/V97ffvst3bt3p2PHjgwbNozDh62HoLi4OB5++GF69OjBxx9/7NcFujfeX/+9e/fmnnvuoUuXLjRv3jzL9cicOXO44IIL2LRpE6+//jrPP/88iYmJ/Pjjj6fEHz9+PJ07d6Z9+/ZcfPHFp0xclMnIkSOz3J1nnltCQkLWgF5fafz0009Mnz6du+66i8TERNavX5+VDsD3339Phw4dSEhIYNSoURw/fjzrejzwwAN07NiRhIQEVq/OOeqg6OGmSuouoI0xJs5rIF++Bu4VF2IqxdClQRftXqsUO8aOhd69A7uMHZt7nmPGjCE1NZWFCxfSsGFD7rjjDvbs2cOjjz7KzJkzWbx4MUlJSTz33HNZccqXL8+8efMYPnw4V199NU899RRLly4lISGBhx46zaH1aaSnp/Prr7/ywgsvnBY+Li6OMWPGcPvtt5Oamnqa76WhQ4eycOFClixZQqtWrXjrrbf85pOUlERqaiqpqakMGDCAO++8028aZ555JoMHD+aZZ54hNTWVJk2aZKVz7NgxRo4cyYcffsiyZctIT0/ntddeyzpeq1YtFi9ezI033pglbEUZN4KxHjhdiksoA5sO5Jetv7DnyJ68AyuKcoor7wULFrBy5UrOOussEhMTefvtt9m8eXNW2EzX5nm5QPfH0KHW31tB3HovX76cs88+m4SEBCZPnsyKFSvyjPPRRx+xePFinnzyyQKl8fvvvxMfH0/z5s2B08+zMOcTDtyMw7gX+ElEfsG6LAfAGHNr0KwKI55mHh6c+yDfrPuGK9tdGW5zFMUVL4THu/lprryNMfTr148pU6b4DJ/TtXl+yXTtnV835WCrm6ZOnUr79u2ZNGkSc+bMyTX8ihUreOCBB/jhhx+y2lvym0ZejisKcz7hwE0J4w1gFrAA236RuZRIOtXvREzFGK2WUpQ88OXKu1u3bsyfP59169YBcOTIEdasWXNa3EC7QM/En7twgEOHDlGvXj3S0tKYPHlyrukcOHCA4cOH88477xATE5NnGv7ybdmyJZs2bcq6HoE6z3DhpoSRboy5I+iWFBEiJIKBzQby1ZqvyDiZQWRE3j05FKU04s+V96RJk7j88suzGncfffTRrCoZbwLpAj2TQYMGcckllzBt2jRefvnlU4498sgjdO3alUaNGpGQkOBXWMD2etq8eTM33HBD1r7U1FS/aQwfPpwbbriBl156KauxG2ybzcSJExk2bBjp6el07tw53z23ihJ+3ZtnBbCz7G0GvuDUKqmwdKsNhnvznHyw/AMu//Ryfr7uZ7o17BbUvBSloKh7c8UfwXJv7qaEcYXze6/XPgOUyJ5SAP2b9CdCIkhem6yCoSiK4uBmitZCz4dR3KhRoQbdG3ZXNyGKoiheuJ0Po62IXCoiV2cuwTYs3HiaeVi0YxG7Du8KtymK4pcwTB+jFHGCeU+4Gen9APCys/QBngYG5xqpBOBp5gHg63Vfh9kSRfFN+fLl2bt3r4qGkoUxhr1791K+fPmgpO+mDeMSoD3wmzHmWhGpA0wIijVFiPZ12lMvuh7J65K5JvGavCMoSohp2LAhW7duZffu3eE2RSlClC9fnoYNGwYlbTeCcdQYc1JE0h0HhH9Sghu8MxERBjYdyGerPyP9ZDplItxcKkUJHVFRUcTHx4fbDKUU4aYNI8WZm3s8dsDeYuDXoFpVRPA087D/2H4WbF0QblMURVHCjpteUjcZY/YbY14H+gHXGGOuDb5p4efcxudSJqKM9pZSFEXBXaP3dZnrxphNwAqnIbzEU7V8Vc6KPUsFQ1EUBXdVUueISLKI1BORtlifUpWDbFeRwdPMw5JdS9h2cFu4TVEURQkrbqqkrgDeBpYBycBYY8ydwTasqJDZvXbGOp1USVGU0o2bKqlmwG3Ap8Am4CoRqRhku4oMbWLaEFslVgVDUZRSj5sqqS+A+40x/wf0AtYCC4NqVREis3vtd+u/40TGiXCboyiKEjbcCEYXY8xMAGN5FrgwuGYVLTzNPBw6cYj5f8wPtymKoihhw41gpIvIf0RkPGRVUbUIrllFi3Man0NURJT2llIUpVTjRjAmYufB6O5sbwUeDZpFRZDostH0iuul7RiKopRq3AhGE2PM00DcKvw9AAAgAElEQVQagDHmKCBBtaoI4mnqYcXuFWzevznvwIqiKCUQN4JxQkQqYCdNQkSa4DXznj9EJFZEZovIKhFZISK3+QjTW0QOiEiqs9yf7zMIEQObDQS0e62iKKUXN4LxAPA1ECsik4HvgbtdxEsH/mGMaQV0A24WkdY+wv1ojEl0lofdGh5qWtRsQXy1eG3HUBSl1JKnC1ZjzHcishj70hfgNmPMHhfxdgA7nPVDIrIKaACsLJzJ4UFE8DTzMDF1IsfTj1OuTLlwm6QoihJSXM24Z4zZa4z5yhjzpRuxyImIxAEdgF98HO4uIktEZIaItPETf7SIpIhISjh9/3uaeTiSdoQfNv8QNhsURVHChSvBKAwiEo0dJT7WGHMwx+HFQCNjTHvsjH5TfaVhjHnTGJNkjEmKiYkJrsG50DuuN+Uiy2m1lKIopZKgCoaIRGHFYrIx5rOcx40xB40xh531ZCBKRGoF06bCUDGqIn3i+5C8TgVDUZTShxtfUjV8LFEu4gnwFrDKGPOcnzB1nXCISBfHnr35O4XQ4mnqYc3eNaz/a324TVEURQkpbkoYi4HdwBqsH6ndwEYRWSwinXKJdxZwFdDXq9usR0TGiMgYJ8wlwHIRWQK8BAw3RXxGe+1eqyhKacXNRNVfA58bY74BEJH+wADgI+BVoKuvSMaYeeQxwM8Y8wrwSn4MDjdNazSlWY1mJK9N5pYut4TbHEVRlJDhpoSRlCkWAMaYb4GexpgFQKnsW+pp5mH2ptkcSTsSblMURVFChhvB+EtE7hGRRs5yN7BPRCKBk0G2r0jiaebhWPox5myaE25TFEVRQoYbwbgCaIjt8joNOMPZFwlcGjzTii49G/WkYlRFZqzVdgxFUUoPbkZ67wH+n5/D6wJrTvGgfJnynBN/DsnrknnJvITT0UtRFKVE46ZbbXMReVNEvhWRWZlLKIwrygxsOpAN+zawZu+acJuiKIoSEtz0kvoYeB2YAGQE15ziQ2b32uS1ybSoVarmk1IUpZTiasY9Y8xrxphfjTGLMpegW1bEiasWR+uY1joeQ1GUUoMbwfhCRG4SkXreo72DblkxwNPUw9zNczl84nC4TVEURQk6bqqkrnF+7/LaZ4DGgTcneGzcCLPy2fKSZ1v27lGcWLiXf41bS4d6HQKbdgjCFiR8MAiEDUUljUCgdpxKUbCjKNgA0LIltGsXvvzd9JKKD4UhwSYlBa6/PtCptgL+x8vTA52uoijK6dxzTxEVDBHpa4yZJSJDfR335X22KHP++fDHH+7Du/VoNfqL0SzbtZz5o+a77l6bH29ZwQpbkPDBIBA2FJU0AoHacSpFwY6iYEMmNWuGN//cShi9gFnAIB/HDFCsBKNiRbsEmku6d+GbL8bzd8WVtKntc/4nRVGUEoFfwTDGPOD8Xhs6c4ofA5tmd69VwVAUpSSTZxuGiJQDLgbivMMbYx4OnlnFhwZVGtCuTjuS1yVz11l35R1BURSlmOKmW+00YAiQDvzttSgOnqYe5v0xj4PHc85AqyiKUnJwIxgNjTGXGWOeNsY8m7kE3bJihKeZh/ST6czcMDPcpiiKogQNN4Lxk4gkBN2SYkz32O5ULVeV5LU617eiKCUXNwP3egAjRWQjcBw7i54xxoSxN3DRokxEGfo36U/y2mSMMeq9VlGUEokbwRgYdCtKAJ5mHj5e+TFLdi0hsW5iuM1RFEUJOHlWSRljNhtjNgNHseMvMhfFiwFNBwDopEqKopRY3MyHMVhE1gIbgbnAJkDfijmoG12XTvU6kbxO2zEURSmZuGn0fgToBqxx/EqdA8wPqlXFlIFNB/LTlp/Yd3RfuE1RFEUJOG4EI80YsxeIEJEIY8xsQCvpfeBp5uGkOcm3678NtymKoigBx41g7BeRaOAHYLKIvIgdxKfkoEuDLtSoUEMnVVIUpUTiRjCGAEeA24GvgfX4dkhY6omMiGRA0wHMWDeDk+ZkuM1RFEUJKLkKhohEAtOMMSeNMenGmLeNMS85VVTFj5PBf4l7mnr48+8/WbxjcdDzUhRFCSW5CoYxJgM4IiJVQ2RP8Pj1V+jUCTZtCmo25zU9D0F01LeiKCUON1VSx4BlIvKWiLyUuQTbsIATEWHFolcv2LAhaNnUqliLLg26qGAoilLicCMYXwH/wTZ6L3KWlGAaFRSSkuyk3n//DT17wpo1QcvK08zDr9t+Zc+RPUHLQ1EUJdS4EYxqTttF1gJUzyuSiMSKyGwRWSUiK0TkNh9hxCmxrBORpSLSsSAn4ZoOHWD2bDhxwpY0Vq0KSjaeZh4Mhm/WfROU9BVFUcKBG8G4xse+kS7ipQP/MMa0wg78u1lEWucIMxBo5iyjgddcpFs4EhJgzhy73qsXLFsW8Cw61utI7Uq1ddS3oiglCr+CISKXi8gXQLyITPdaZgN59pIyxuwwxix21g8Bq4AGOYINAd4xlgVANRGpV+CzcUvr1jB3LpQtC336QGpqQJOPkAgGNB3A1+u+JuNkRkDTVhRFCRe5lTB+Ap4FVju/mcs/gAH5yURE4oAOwC85DjUAtnhtb+V0UUFERotIioik7N69Oz9Z+6d5cysalSpB376QEthmGU9TD38d/YuF2xcGNF1FUZRw4VcwHC+1c4wx3Y0xc72WxcYY1yO9nVHinwJjjTE55zD1NXHEaZ5wjTFvGmOSjDFJMTExbrPOmyZNrGhUqwbnnAMLFgQs6f5N+hMhEdpbSlGUEoObNowCIyJRWLGYbIz5zEeQrUCs13ZDYHswbTqNuDgrGrVrQ79+MG9eQJKtXqE63Rt2V8FQFKXEEDTBEDvt3FvAKmPMc36CTQeudnpLdQMOGGN2BMsmv8TGWtFo0ADOOy+7UbyQeJp5WLRjETsP7wxIeoqiKOEkT9cgIvJeAdM+C7gK6Csiqc7iEZExIjLGCZMMbADWAeOBmwqYV+GpX9+KRnw8eDzw3XeFTtLTzAOg3WsVRSkR5DpFqzEmQ0RiRKSsMeZEfhI2xszDdxuFdxgD3JyfdINKnTp2nEa/fjBoEHz+OQws+Ay17eu0p150PZLXJXNNoq/eyYqiKMUHN3N6bwLmi8h04O/MnblUMxVvYmLsiPD+/eHCC+Hjj2Hw4AIlJSJ4mnn4ZOUnpJ9Mp0yEm8utKIpSNHHThrEd+NIJW9lrKbnUqAEzZ9qR4RdfDJ9+WuCkBjYdyIHjB/h5y88BNFBRFCX05PnJa4x5CEBEKhlj/s4rfImhWjX49ltbJXXZZfDeezB8eL6TObfxuZSJKMOMdTM4u9HZQTBUURQlNORZwhCR7iKyEjtSGxFpLyKvBt2yokCVKvDNN9CjB1x5Jbz7br6TqFq+Kj3O6KHdaxVFKfa4qZJ6ATgPxx2IMWYJ0DOYRhUpoqMhOdmOBr/mGvjf//KdhKephyW7lrDt4LYgGKgoihIaXI3DMMZsybGrdDlIqlgRpk+3YzSuuw5efz1f0Qc2sz2tdK5vRVGKM24EY4uInAkYESkrInfiVE+VKipUgKlTbXfbG2+El9zPIdUmpg2xVWK1WkpRlGKNG8EYgx0r0QDYBiRSlMZOhJJy5eCTT+Cii+C22+DZZ11Fy+xeO3PDTE5k5Gs4i6IoSpEhT8EwxuwxxlxpjKljjIkxxowwxuTp3rzEUrYsfPih7Tl1553wxBOuonmaeTh04hDz/5gfZAMVRVGCg5teUo1F5AsR2S0if4rINBFpHArjiixRUbab7YgR8K9/wUMPgTnNye4p9I3vS9nIslotpShKscVNldT7wEdAPaA+8DEwJZhGFQvKlIFJk+Daa+HBB+G++3IVjeiy0fRs1FNn4VMUpdjiRjDEGPOuMSbdWd7Dx5wVpZLISJgwAUaPhscfh7vvzlU0PE09rNy9ks37N4fQSEVRlMDgRjBmi8g/RSRORBqJyN3AVyJSQ0RqBNvAIk9EhO1me8stMG4cjB3rVzQyvddq91pFUYojbrzhXeb8/l+O/aOwJY3S3Z4BIGK72ZYtC889B2lp8MorVky8aF6zOY2rNyZ5bTJjksb4SUxRFKVo4saXVHwoDCn2iNgSRtmy8OSTcOIEvPGGrbbKCiKc3+x8Xkt5jWfmP8Md3e8gMiIyl0QVRVGKDupvO5CI2LaMsmXh4YetaEyceIpoPNj7QbYd2sbdM+/mk1WfMHHIRFrHtA6j0YqiKO4I6pzepRIR2832kUess8IRIyA9PetwjQo1+GTYJ3x4yYds2LeBDm904PEfHyf9ZHouiSqKooQfFYxgcd998NRT8MEH1i16WlrWIRHh0jaXsvKmlVzY8kL+PevfdJ3QlaW7lobRYEVRlNxxM3DvLBGp5KyPEJHnRKRR8E0rAdx9Nzz/vJ2AadgwOH78lMMxlWL48JIP+WTYJ2w9uJWkN5N4aM5D6j5EUZQiiZsSxmvAERFpD9wNbAbeCapVJYmxY+G//4Vp02DoUDh27LQgF7e+mJU3rWRYm2E8OPdBuozvwm87fguDsYqiKP5xIxjpxhgDDAFeNMa8SEmfojXQ3HQTjB8PM2bY+cGPHDktSM2KNZk8dDLThk9j19+76DKhC/+Z9R+Opx/3kaCiKErocSMYh0TkXmAEdsBeJBAVXLNKINdfb3tMzZwJAwbA9u0+gw1uMZiVN63kyoQrefTHR+n0ZidStqeE2FhFUZTTcSMYlwHHgeuMMTuxbs6fCapVJZVrroH334eUFEhIsG0bPqheoTqTLpzEV1d8xf5j++k6oSv/nPlPjqWfXp2lKIoSKlyVMLBVUT+KSHPsfBjqfLCgDB8OqanQpAlccgmMHAkHD/oM6mnmYcVNK7g28Vqemv8UHd7owIKtC0Jrr6IoioMbwfgBKCciDYDvgWuBScE0qsTTvDnMnw/332/dpLdvDz/+6DNo1fJVmTB4At+M+IYjaUc4639ncee3d3I07WiIjVYUpbTj1lvtEWAo8LIx5iKgTXDNKgVERdkBfvPm2ZHgvXrBvffa0eE+6N+kP8tuXMbojqN59udnaf96e+b9MS/ERiuKUppxJRgi0h24EvjK2acOkAJFt262iur6660Pqq5dYcUKn0GrlKvCaxe8xvdXf0/ayTR6TuzJ2K/H8veJv0NstKIopRE3gjEWuBf43Bizwpltb3ZwzSplREfDm2/asRrbtkGnTvDii3DypM/gfeP7suzGZdzc+WZe/OVF2r3ejjmb5oTWZkVRSh1u5vSea4wZDLwqItHGmA3GmFtDYFvpY/BgWLYM+vWzA/4GDLAC4oPostG87HmZuSPnIgh93u7DzV/dzOETh0NstKIopQU3rkESROQ3YDmwUkQWiUiebRgi8j9nDvDlfo73FpEDIpLqLPfn3/wSSJ06MH26dY0+f77tfvvRR36D92zUk6U3LuX2brfzWsprtH21LTM3zAyhwYqilBbcVEm9AdxhjGlkjDkD+Acw3kW8ScCAPML8aIxJdJaHXaRZOhCx076mptoeVZddBlddBQcO+AxeMaoiz533HPNGzaNcmXL0e7cfo78YzcHjvrvrKoqiFAQ3glHJGJPVZmGMmQNUyiuSMeYH4K+Cm6bQrJntRfXggzBlCrRrB3Pn+g1+ZuyZpP5fKnedeRdv/fYWbV9tyzfrvgmdvYqilGjcCMYGEfmPM6d3nIjcB2wMUP7dRWSJiMzIrZpLREaLSIqIpOzevTtAWRcTypSBBx6w1VPlykGfPtYL7nHfPqYqRFXg6X5P89Oon6hcrjIDJg9g1LRR7D+2P8SGK4pS0nAjGKOAGOAz4HNn/doA5L0YaGSMaQ+8DEz1F9AY86YxJskYkxQTExOArIshXbvCb7/ZqqpnnoEuXWwDub/gDbuyePRi/tXjX7yz5B3avNqGL9d8GUKDFUUpabjpJbXPGHOrMaajMaaDMeY2Y8y+wmZsjDlojDnsrCcDUSJSq7DplmgqVYLXX4cvv4SdOyEpCZ57zm/323JlyvHYOY/xy/W/ULNCTQZNGcRVn1/FX0e1plBRlPzjVzBE5AsRme5vKWzGIlJXRMRZ7+LYsrew6ZYKzj8fli+HgQPhH/+w3XC3bPEbvFP9TqSMTuH+nvfzwfIPaP3f1kxd7bdApyiK4hOxU134OCDSK7eIxhj/ra82/hSgN1AL2AU8gOMW3RjzuojcAtwIpANHsT2xfsrL4KSkJJOSou6+ATAG/vc/uO0262rk1Vfh8stzjZK6M5Vrp11L6s5UBrcYzF1n3sVZsWfhaLeiKCUUEVlkjEkqVBr+BKOoooLhg/Xrbbfbn3+2gvHf/0L16n6Dp2Wk8cxPzzDup3HsO7aPpPpJjO06lmFthlE2smwIDVcUJVQEQjDcNHorRZ0mTeCHH+CRR+wgv3btYNYsv8GjIqP419n/YsvtW3jt/Nc4fOIwIz4fQdwLcTz2w2PsObInhMYrilJcUMEoKZQpA/fdZ0sZlSrBOefY9g0fc4hnUqlsJcYkjWHFTSuYceUM2tVpx32z7yP2+VhGfzGaFX/6doKoKErpxLVgiEieg/WUIkDnzrB4sZ1H/Lnn7PbSpblGiZAIBjQdwNcjvmbFTSu4ut3VvLv0Xdq+1pb+7/YneW0yJ43vnliKopQe3PiSOlNEVgKrnO32IvJq0C1TCk7FirYdIzkZ9uyxojFunN/ut960jmnNG4PeYOvtW3m87+Os2L2C898/n1b/bcWrC19VV+qKUopxU8J4HjgPp8urMWYJ0DOYRikBYuBAO7jv/PPhrrtsNdUff7iKWrNiTe49+1423baJ94e+T9VyVbk5+WYaPt+Qe767hz8OuEtHUZSSg6sqKWNMzk7+GUGwRQkGtWrBp5/a7rcpKbZBfPJk2yXXBVGRUVyecDm/XP8LP436iX6N+zHu53E0frExl31yGT9v+Zni1tNOUZSC4UYwtojImYARkbIicidO9ZRSTBCBa6+FJUugbVsYMQKGD4e/3I/4FhG6x3bno2EfseHWDdzR/Q6+WfcNZ/7vTLq91Y0py6aQlpEWxJNQFCXcuBGMMcDNQANgK5DobCvFjcaNrbfbxx6Dzz6Dpk2tY8O9+Rtg36haI57u9zRb79jKfz3/Zf+x/Vzx2RXEvxjPk/OeZO8RHbCvKCURHbhXWklNtW7Tp02z3XBHj7bdcBs0yHdSJ81JZqydwQu/vMDMDTOpUKYCV7e/mtu63karmFaBt11RlHwTkpHeIvKSj90HgBRjzLTCZF4QVDACzIoV8NRT8P77EBEBV18N99xj5+IoAMv/XM6LC17k3aXvcjzjOOc1OY+x3cZyXpPz1P2IooSRUI30Lo+thlrrLO2AGsB1IvJCYTJXigBt2sA778C6dXDDDbZBvEULO8vfb7/lO7m2tdsyfvB4tty+hUf7PMrSXUsZOHkgbV5twxspb3Ak7UgQTkJRlFDgpoQxC+hvjEl3tssA3wL9gGXGmNZBt9ILLWEEmV274IUXrCPDgwdhwAC49144+2zbeJ5PTmSc4KMVH/H8gudZvGMxNSrUYHTH0dzc5WYaVmkYhBNQFMUXoSphNODUKVkrAfWNMRmA72nflOJLnTrwxBOwebNtHF+0CHr1gh497Dwc+WzzKhtZlhHtRpByQwo/XvsjfeL68PRPTxP/YjxXfHoFv277NUgnoihKoHFTwrgOuA+YAwh20N7jwBTgQWPMXUG28RS0hBFijhyxYzieecYO+ktIsCWOYcOs/6oCsHHfRl759RUm/DaBg8cP0rZ2W4a0GMLgFoNJqp9EhKiLM0UJNCFzby4i9YAuWMH41RizvTCZFgYVjDCRlgZTpsCTT8KqVbaL7t13wzXXQPnyBUry0PFDvLPkHT5Z9Qk/bv6RDJNBveh6DG4xmMEtBtM3vi/lyxQsbUVRTiWUglEdaIZtAAfAGPNDYTIuKCoYYebkSZg+HR5/HBYuhLp14Y47YMwYqFy5wMn+dfQvktcmM+33aXy97msOnzhMpahKnNf0PIa0GML5zc6nZsWaATwRRSldhKpb7fXAbUBDIBXoBvxsjOlbmIwLigpGEcEYO+fGE0/A999DtWpwyy129r9ahZua/Xj6cWZvms201dOYvmY62w9tJ0Ii6HFGD4a0GMKQFkNoUqNJgE5EUUoHoRKMZUBnYIExJlFEWgIPGWMuK0zGBUUFowjy669WOKZOtZ5yb7jBDgKMjS100sYYFu1YlCUeS3dZV+2tY1pntXt0adBF2z0UJQ9CJRgLjTGdRSQV6GqMOS4iqcaYxMJkXFBUMIowK1faQYCTJ9tBgCNG2EGALVoELIuN+zbyxZovmPb7NOZumkuGyaBOpToMaj6IIS2HcE78OVSIqhCw/BSlpBAqwfgcuBYYC/QF9gFRxhhPYTIuKCoYxYDNm+38GxMmwPHjcPHFtmdVx44BzWbf0X3MWDeDab9PY8baGRw6cYiKURXp36Q/Q1oM4YLmF1CrYuGqxxSlpBCyRm+vDHsBVYGvjTEnCpNxQVHBKEb8+Se8+CK88oodBNi/vxWOXr0KNAgwN46nH2fOpjlM/30609dMZ+vBrURIBGfGnplVddW8ZvOA5qkoxYmgC4aIRABLjTFtC5NJIFHBKIYcOACvvQbPP29FpFs3KxwXXGCrrgKMMYbFOxYz/ffpTPt9Gkt2LQGgZa2WWeLRtUFXIiMiA563ohRVQlUlNRm41xhTJKZYU8Eoxhw9ChMnwtNP22qrtm3hn/+0fqsKOAjQDZv2b+KL3512j81zST+ZTu1Ktbmg2QUMaTmEcxufS8WoikHLX1GKAqESjFnYXlK/AlkTOhtjBhcm44KiglECSEuDDz6wgwBXroSaNWHQILjoIujXDyoEr9F6/7H9zFjrtHusm8HB4wepUKYC/Zr0o0dsDxLrJpJYN5GYSjFBs0FRwkGoBKOXr/3GmLmFybigqGCUIE6ehORk+PBD66dq/37bLXfAABg61M5FXq1a0LI/kXGCuZvmMu33aXy19is27d+Udax+5fok1k2kQ90OWSLSuHpj7b6rFFtCOdK7EdDMGDNTRCoCkcaYQ4XJuKCoYJRQ0tJgzhz4/HM7nmPHDltN1aePLXlceCHUqxdUE/Ye2cuSXUv4bcdvpO5KJXVnKqt2ryLD2Cnso8tG075O+ywB6VC3A21qt1H3JUqxIFQljBuA0UANY0wTEWkGvG6MOacwGRcUFYxSwMmTdjDg55/bZe1au79bNyseF11U4Ame8sux9GOs+HMFqTutgPy28zeW7FrC4ROHAYiUSFrFtLIiUicxS0zUjYlS1AiVYKRiHQ/+Yozp4OxbZoxJKEzGBUUFo5RhjG3nyBSPxYvt/jZtssWjQ4eAd9PNjZPmJBv2bcgSkcxl26FtWWFiq8RmiUfmEl8tXmcdVMJGqATjF2NMVxH5zRjTwZlAabExpl0e8f4HXAD86atbrtgn50XAAxwBRhpjFudlsApGKWfzZltl9fnn8OOPtjTSqJGtsrroIjtvR2R4usvu/nt3toA4VVqr96zmpDkJQJVyVWhfp/0p7SKtY1pTrky5sNirlC5CJRhPA/uBq4H/B9wErDTG/DuPeD2Bw8A7fgTD46TnAboCLxpjuuZlsAqGksXu3fDFF1Y8vvvOjiqvVQsGD7bice65BXa9HiiOph1l+Z/LT6vSypyqtkxEGVrHtD6lSqtdnXZapaUEnFAJRgRwHdAfOx/GN8AE46K1XETigC/9CMYbwBxjzBRn+3egtzFmR25pqmAoPjl8GL7+2orHl1/akeXR0TBwoBUPjweqVg23lQBknMxg/b71p1Vp7TicfevXr1yfhNoJtKvTLuu3Za2WWhpRCkyoBOMiINkYk+/pWPMQjC+BJ40x85zt74F7jDG5qoEKhpInJ07A7NlWPKZNg507ISoK+va14jFkiJ3Ho4ix6/AuUnemsuzPZSz7cxlLdy1l5e6VnMiwXnjKRJShRc0WJNRJoF3tdva3Tjtiq8Rq24iSJ6ESjIlYp4M/AB8A3xhj0l0aGId/wfgKeCKHYNxtjFnkI+xobE8tzjjjjE6bN292k72i2DaOBQuyG83Xr7cN5N27ZzeaNym6c2ukZaSx9q+1LNtlBSRTSDYfyH4GqparStvabU8pjbSt3Zaq5YtGiUopGoRyHEYUMBC4DOgBfGeMud5FvDi0SkopKhgDy5dni0dqqt2fkGCFo29fSEqCSpXCa6cLDhw7wPI/l2cJSObvweMHs8I0qtrotNJI85rNKRMRPDcsStElpN5qHdEYgHV1frYxJk/fCXkIxvnALWQ3er9kjOmSV5oqGErA2Lgxu8fVvHlWUCIjrYB065a9NG8e0m67BcUYw5aDW6yA7FrG0j/t7+o9q7MGH5aNLEvrmNantY/Uja6r1VolnFBVSQ0AhgN9gDnAh8C3eVVLicgUoDdQC9gFPABEARhjXne61b6CFaEjwLV5tV+ACoYSJPbuhV9+sdVXCxbY9YPO13r16tC1a7aAdOli9xUTjqcfZ/We1aeVRrYf2p4VpmaFmqeURtrWbkvj6o2JqRijQlJCCJVgfIBtu5hRkIbvQKOCoYSEkydh9epsAVmwwFZnZT4vrVqdWgpp0yZs4z8Kyt4je20Du1f7yLI/l2V1+QWoFFWJuGpxxFePJ76as1TP/q1SrkoYz0DJDyGfQMnJ9CzgCmPMzYXJuKCoYChh4+BBSEnJFpCff4Y9e+yxSpVsySNTQLp2hTp1wmtvAThpTrJx30ZW7l7Jxv0b2bhvo/111g+dONWFXI0KNU4VEa/1RtUaqZ+tIkQoG70TgSuAS4GNwGfGmJcLk3FBUcFQigzG2HYQ71LIb79BulNbGx9/aikkMRHKlg2vzYXAGMNfR/86VUi8BGXT/k1ZXYAzqRddz2/ppGGVhtoAH0KCKhgi0hzbdnE5sBfbdnGnMaZRYTIsLCoYSpHm6FErGt4ismWLPVaunJ3X3FtEYmOLRYO6G06ak+w4tMOnkGzct5EtB7dkuUkBOxqPHR4AAAs6SURBVK4ktkqsX0GpU6mOtp8EkGALxkngR+A6Y8w6Z98GY0zjwmRYWFQwlGLHtm2nCkhKChw7Zo/Vq3eqgHTqVCy69RaEtIw0thzc4rN0snHfRnb9veuU8BXKVKBRtUbEVonljKpnEFslltiqsdnbVWN1psR8EGzBuAhbwjgT+Brb8D3BGBNfmAwLiwqGUuxJS4OlS08VkXXr7LGICGjcGFq2tA3rrVplrwdxMqmiwJG0I1mlkUwR2XxgM1sObuGPA3+w8/DO0+LUqFAjW0y8hCRTXBpUbkBUZFQYzqboEapeUpWAC7FVU32Bt4HPjTHfFibjgqKCoZRI9uyxXXkXLrTu3FevhjVrrEPFTOrWzRYPb0Fp0KDEVGvlxomME2w7uC1LQLYc2JK9fnALWw5sYd+xfafEEYR6leudVkrxXq9dqXapmEkx5L2kRKQGMAy4zBjTtzAZFxQVDKXUkJFhG9VXr4ZVq7J/V62y09lmEh1tBSRnqaRpU+tDqxRx+MThU4XEWffePpp+9JQ4ZSPL0rBKw2wxqXLGaVVfVctVLfbtKWHpVhtuVDCUUo8x8Oef2eLhLSiZDexgp7ht2vT0UknLllC5cvjsDyOZPb28SyVZ646obDu4LWtkfCZVy1WlWc1mNKvhLDWzf2tUqBGms8kfKhiKopzKoUPw+++nl0rWrs3u7gu2Gitn1VbLlrbaq5h/SReWjJMZ7Dy88xRR2bBvA2v/Wsvav9ayef9mDNnvzRoVapwqIl7rRckBpAqGoijuSEuDDRt8l0oOeQ3Gq1rVCkeLFhAXZ2czPOMM+xsbG/YJqYoCx9OPZwvI3rVZQrJ271q2HNxyStiYijE+haRpjaZULhfaUp4KhqIohcMY2L79dBFZs8Z2B875fqhbN1tAMhfv7apVS3UJ5WjaUdbvW58tJF6C4u27C6BudF2fVVxNqjehUtnAd61WwVAUJXikpcHWrXYe9T/+sL+Zyx9/2CVzPEkmlSv7F5MzzrDjTiJKfo8kX/x94m/W/bXOZ8kk5xiU+pXr+xWTClEVCpS/CoaiKOEjs/E9p6B4r+87tZsrUVG2astfKaWUVnsdPH6Q9X+t9ykmu4/szgo3tutYnh/wfIHyCIRgqCMXRVEKhoh1sFinjnW86ItDh/yLycyZtjos50drnTrZQhIba6vBvJd69aBGjRJVUqlSrgod6nWgQ70Opx3bf2y/LZnsXUvTGk3DYF02WsJQFCV8eFd7+SqpbNli/XPlpEwZKyw5xcTXEh0d+vMqgmgJQ1GU4k1UlPXqG+/H45AxcPgw7Nzpf9m+HRYvttVjGRmnpxEd7U5YatcudQMd84sKhqIoRRcR25BeuTI0a5Z72IwMO3NibuKyYgV8//3pbSuZ1KqVXe3lLSYxMfZYzZrZv1WqlLoeYSoYiqKUDCIjbSmhdm1o1y73sMeO2RLJzp2wY4dvcVm71h477mei0TJlrHB4i0jmr699tWpZB5LFuO1FBUNRlNJH+fK2Z9YZZ+Qezhg4cMA6h9yzx5Zg/P2uXWtnYdy717bN+CIiws4H70ZgMtdr1LDiVAQoGlYoiqIURURsqaBaNeuXyw3G2N5h3mLiT2g2b4ZFi+x2zjEt3lSrZgXkppvgjjsCc24FQAVDURQlkIjY9o0qVfw35vviyBH/pZfM9TDPE6+CoSiKUhSoWNFdNVkYKb6tL4qiKEpIUcFQFEVRXKGCoSiKorhCBUNRFEVxhQqGoij/v737D/WrruM4/nxx78ptJtqmYzp1hcNMyTllrAajXIWmmBmhUiIhJSE5I/r5Twj9kRBRUgTmzEVrYdNRRIyNZUZoE50ut6ZIumx59W6ULTXWXK/+OJ9b391tcHbv7vl8x/f1gMs533Pv9nndc+8973M+53w/n4hWUjAiIqKVFIyIiGglBSMiIlo57ubDkLQb+PME//lsYM8xjDNRyXGw5DhYP+TohwyQHONNJsfZtk+dTOPHXcGYDEmPTXYCkeRIjkHI0Q8ZkqP/cqRLKiIiWknBiIiIVgatYNxVO0CRHAdLjoP1Q45+yADJMV7VHAN1DyMiIiZu0K4wIiJiglIwIiKilYEoGJLukTQqaVvlHGdKelDSDknbJa2olOMESY9K2lpy3F4jR8kyJOkJSb+smGGnpKckPSnpsYo5Tpa0VtLT5Xfk3RUynFv2w9jHXkm3dZ2jZPlc+f3cJmmNpBMqZFhR2t/e9X443HFL0lslbZT0bFme0mWmgSgYwL3AZbVDAG8An7d9HrAEuEXSOyvk2AdcavtCYCFwmaQlFXIArAB2VGq71/tsL6z8rP13gPW23wFcSIX9YvuZsh8WAhcDrwPrus4h6QzgVuAS2xcAQ8B1HWe4APgUsJjm53GlpAUdRriXQ49bXwY22V4AbCqvOzMQBcP2b4G/9UGOEdtbyvo/aQ4IZ1TIYduvlpfTykfnTz9ImgdcAdzdddv9RtJJwDJgJYDtf9t+pW4qlgN/sj3RkRUmaxiYLmkYmAG82HH75wG/t/267TeAh4CPdNX4EY5bHwZWlfVVwNVd5YEBKRj9SNJ84CJgc6X2hyQ9CYwCG23XyPFt4IvAfyq03cvABkmPS/p0pQxvB3YDPyxddHdLmlkpy5jrgDU1Grb9V+CbwAvACPAP2xs6jrENWCZplqQZwIeAMzvOMN4c2yPQnIACp3XZeApGBZJOBO4HbrO9t0YG2wdKt8M8YHG5/O6MpCuBUduPd9nuESy1vQi4nKabcFmFDMPAIuD7ti8CXqPj7oZekt4EXAX8rFL7p9CcTb8NOB2YKekTXWawvQO4A9gIrAe20nQrD6wUjI5JmkZTLFbbfqB2ntLt8Ru6v8ezFLhK0k7gp8Clkn7ccQYAbL9YlqM0/fWLK8TYBezqudJbS1NAarkc2GL75Urtvx943vZu2/uBB4D3dB3C9krbi2wvo+keerbrDOO8LGkuQFmOdtl4CkaHJImmj3qH7W9VzHGqpJPL+nSaP86nu8xg+yu259meT9P18WvbnZ5BAkiaKektY+vAB2m6Ijpl+yXgL5LOLZuWA3/sOkeP66nUHVW8ACyRNKP83SynwkMAkk4ry7OAa6i7TwB+AdxY1m8Eft5l48NdNlaLpDXAe4HZknYBX7O9skKUpcANwFPl/gHAV23/quMcc4FVkoZoThrus13tsdbK5gDrmmMSw8BPbK+vlOWzwOrSHfQc8MkaIUp//QeAm2u0D2B7s6S1wBaabqAnqDMsxv2SZgH7gVts/72rhg933AK+Adwn6SaaovqxrvJAhgaJiIiW0iUVERGtpGBEREQrKRgREdFKCkZERLSSghEREa2kYESMI+nAuBFbj9k7riXNrz1qcsREDcT7MCKO0r/KsCkR0SNXGBEtlXkz7ihziTwq6Zyy/WxJmyT9oSzPKtvnSFpX5h3ZKmlsaIshST8ocyxsKO+2j+h7KRgRh5o+rkvq2p7P7bW9GPguzWi7lPUf2X4XsBq4s2y/E3iozDuyCNheti8Avmf7fOAV4KNT/P1EHBN5p3fEOJJetX3iYbbvpJl46rkyiORLtmdJ2gPMtb2/bB+xPVvSbmCe7X09/8d8muHkF5TXXwKm2f761H9nEZOTK4yIo+MjrB/paw5nX8/6AXIvMY4TKRgRR+fanuUjZf1h/j996MeB35X1TcBn4H8TVp3UVciIqZAzm4hDTe8ZTRiaebbHHq19s6TNNCdb15dttwL3SPoCzax5Y6PMrgDuKiOLHqApHiNTnj5iiuQeRkRL5R7GJbb31M4SUUO6pCIiopVcYURERCu5woiIiFZSMCIiopUUjIiIaCUFIyIiWknBiIiIVv4Ls3Hj6ohakgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "initializations = [\"glorot\", \"normal\", \"zero\"]\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "n_epochs = 10\n",
    "xrange = np.arange(n_epochs) + 1\n",
    "\n",
    "for init, c in zip(initializations, colors):\n",
    "    \n",
    "    np.random.seed(6135)\n",
    "    \n",
    "    neural_net = NN(hidden_dims, n_hidden, mode, datapath, model_path,\n",
    "                    batchsize, lr, delta, activation, initialization=init)\n",
    "    neural_net.display_network(init.upper() + \" INITIALIZATION:\")\n",
    "    \n",
    "    neural_net.train(train_data, train_labels, n_epochs)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    plt.plot(xrange, neural_net.losses, color=c, label=(init + \" initialization\"))\n",
    "\n",
    "plt.title(\"Average loss per training example over the first 10 epochs\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average loss per traning example\")\n",
    "plt.xticks(xrange)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search using glorot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed settings for building our networks\n",
    "n_hidden = 2\n",
    "mode = 'train'\n",
    "datapath = None\n",
    "model_path = None\n",
    "initialization = \"glorot\"\n",
    "\n",
    "# don't display loss nor valid success rate at the end of each epoch\n",
    "verbose = False\n",
    "\n",
    "# early stopping hyperparameters\n",
    "max_number_of_epochs = 15\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 95.75%\n",
      "Reached after 15 epochs and 0:02:25.243072 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 94.97%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 94.47%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 89.84%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 88.48%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 87.46%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 63.91%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 58.68%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 55.61%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 65.47%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 53.82%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 43.69%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 31.0%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 34.06%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 31.91%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 11.3%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 94.49%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.62%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 93.11%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 89.99%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 88.92%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 88.33%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 75.82%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 72.7%\n",
      "{'batchsize': 256, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 71.14%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.22%\n",
      "Reached after 15 epochs and 0:01:38.920869 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 95.42%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.01%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.68%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.55%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 88.78%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 73.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 67.67%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 64.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 84.53%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 80.29%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 77.65%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 52.55%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 42.42%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.17%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 10.66%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 94.22%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.25%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 92.84%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.38%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.58%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.13%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 81.06%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 78.85%\n",
      "{'batchsize': 256, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 77.45%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.54%\n",
      "Reached after 15 epochs and 0:01:33.780279 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 95.72%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.48%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.12%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.41%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.9%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 75.54%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 71.68%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 69.23%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 86.55%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 84.35%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 82.39%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 56.17%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 44.69%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.43%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 12.08%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 93.89%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 93.06%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 92.81%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.47%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 89.98%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.6%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 82.96%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 80.18%\n",
      "{'batchsize': 256, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 78.6%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 96.82%\n",
      "Reached after 15 epochs and 0:01:16.555770 time\n",
      "\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.23%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.72%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.87%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 90.47%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 79.89%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 75.3%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 72.66%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 87.32%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 85.21%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 83.52%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 53.33%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 42.83%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 36.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 14.81%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 14.91%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 14.75%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 95.3%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 94.46%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 94.01%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 90.88%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.31%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 89.99%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 84.46%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 82.13%\n",
      "{'batchsize': 256, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 80.5%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 97.9%\n",
      "Reached after 15 epochs and 0:03:19.185112 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.85%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.71%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.15%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 94.09%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 93.47%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 88.94%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 87.23%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 85.97%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 90.9%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 90.49%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 89.97%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 80.37%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 73.95%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 69.56%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 36.84%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 30.33%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 26.52%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.24%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.23%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.1%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.88%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 93.02%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.56%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 89.43%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 88.18%\n",
      "{'batchsize': 32, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 87.41%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best success rate: 98.07%\n",
      "Reached after 15 epochs and 0:02:49.263820 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.98%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.59%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 94.73%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 94.16%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.07%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 88.59%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 87.76%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 91.51%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 91.35%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.21%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 83.92%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 79.87%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 77.29%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 44.52%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 34.5%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 27.73%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.42%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.32%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.06%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.53%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 92.76%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.5%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 89.92%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.08%\n",
      "{'batchsize': 32, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 88.44%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.1%\n",
      "Reached after 13 epochs and 0:03:08.472713 time\n",
      "\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 95.91%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 95.32%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 94.76%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.7%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.79%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 88.8%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 91.63%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 91.58%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.42%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 85.55%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 82.45%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 80.39%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 48.4%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 36.32%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 28.77%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.53%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.48%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.23%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 93.35%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 92.81%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 92.56%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.12%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.54%\n",
      "{'batchsize': 32, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.29%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 98.09%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.1%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.08%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 96.3%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 95.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 95.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 91.2%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 90.31%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.83%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 92.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 92.13%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 91.91%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 86.1%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 83.11%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 80.88%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 46.29%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 35.46%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 30.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.62%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.49%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.32%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 94.77%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 93.92%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 93.6%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 90.51%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 89.92%\n",
      "{'batchsize': 32, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 89.52%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.23%\n",
      "Reached after 12 epochs and 0:13:13.874125 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.08%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.15%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.62%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.49%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 94.53%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 93.28%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.83%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.37%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.14%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.28%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 90.79%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 90.69%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 74.82%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 66.93%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 63.72%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.58%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.56%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.57%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.22%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.14%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 96.97%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 93.29%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.47%\n",
      "{'batchsize': 4, 'hidden_dims': (128, 4096), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.12%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.26%\n",
      "Reached after 10 epochs and 0:12:52.735666 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "Best success rate: 98.3%\n",
      "Reached after 10 epochs and 0:12:54.972299 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.26%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.89%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.86%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 95.09%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 94.08%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 93.55%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.14%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 95.75%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.47%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.26%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.02%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 81.1%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 76.07%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 72.53%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.79%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.78%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.68%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.45%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.09%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 96.93%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 93.01%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.47%\n",
      "{'batchsize': 4, 'hidden_dims': (256, 2048), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.21%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.32%\n",
      "Reached after 9 epochs and 0:15:06.377766 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Success rate: 98.21%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.2%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 98.04%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 98.01%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.93%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 95.55%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 94.67%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 94.18%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.45%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.34%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 91.39%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.43%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.09%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 83.58%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 79.61%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 76.58%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.96%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.71%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.92%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.43%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.22%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.02%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 92.95%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 92.49%\n",
      "{'batchsize': 4, 'hidden_dims': (512, 1024), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 92.27%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.5}\n",
      "Best success rate: 98.33%\n",
      "Reached after 15 epochs and 0:15:43.331946 time\n",
      "\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 98.29%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 98.27%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 98.1%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 98.02%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.95%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 96.01%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 95.16%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'ReLU', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 94.79%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 96.68%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 96.33%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 96.07%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 92.16%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 91.8%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 91.46%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 84.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 80.36%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'sigmoid', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 77.61%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.5}\n",
      "   Success rate: 97.34%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.75}\n",
      "   Success rate: 97.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.1, 'delta': 0.9}\n",
      "   Success rate: 97.2%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.5}\n",
      "   Success rate: 97.56%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.75}\n",
      "   Success rate: 97.26%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.01, 'delta': 0.9}\n",
      "   Success rate: 97.1%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.5}\n",
      "   Success rate: 94.24%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.75}\n",
      "   Success rate: 93.5%\n",
      "{'batchsize': 4, 'hidden_dims': (1024, 128), 'activation': 'tanh', 'lr': 0.001, 'delta': 0.9}\n",
      "   Success rate: 93.13%\n"
     ]
    }
   ],
   "source": [
    "best_success_rate = 0\n",
    "\n",
    "# testing all combinations of a subset of hyperparameters\n",
    "for batchsize in [256, 32, 4]:\n",
    "    for hidden_dims in [(128, 4096), (256, 2048), (512, 1024), (1024, 128)]:\n",
    "        for activation in [\"ReLU\", \"sigmoid\", \"tanh\"]:\n",
    "            for lr in [.1, .01, .001]:\n",
    "                for delta in [.5, .75, .9]:\n",
    "                    \n",
    "                    start_time = datetime.now()\n",
    "                    \n",
    "                    params = {\n",
    "                        \"batchsize\": batchsize,\n",
    "                        \"hidden_dims\": hidden_dims,\n",
    "                        \"activation\": activation,\n",
    "                        \"lr\": lr,\n",
    "                        \"delta\": delta,\n",
    "                    }\n",
    "                    \n",
    "                    print(params)\n",
    "                    \n",
    "                    # instantiate the network\n",
    "                    np.random.seed(6135)\n",
    "                    neural_net = NN(hidden_dims, n_hidden, mode, datapath, model_path,\n",
    "                                    batchsize, lr, delta, activation, initialization)\n",
    "                    \n",
    "                    # reset success rate and patience for the new network\n",
    "                    current_success_rate = 0\n",
    "                    patience_timer = 0\n",
    "                    \n",
    "                    # train until 'max number of epochs' of no progress during 'patience' number of epochs \n",
    "                    while patience_timer < patience and neural_net.epoch_cnt < max_number_of_epochs:\n",
    "                        neural_net.train(train_data, train_labels, n_epochs=1, verbose=verbose)\n",
    "                        success_rate = neural_net.test(valid_data, valid_labels, verbose=verbose)\n",
    "                        if success_rate > current_success_rate:\n",
    "                            current_success_rate = success_rate\n",
    "                            patience_timer = 0\n",
    "                        else:\n",
    "                            patience_timer += 1\n",
    "                            \n",
    "                    # if current network is better on valid set, save as new best network\n",
    "                    if current_success_rate > best_success_rate:\n",
    "                        \n",
    "                        best_success_rate = current_success_rate\n",
    "                        best_epoch = neural_net.epoch_cnt - patience_timer\n",
    "                        best_params = params\n",
    "                        \n",
    "                        print(\"Best success rate:\", best_success_rate, end=\"%\\n\")\n",
    "                        print(\"Reached after\", best_epoch, \"epochs and\",\n",
    "                              datetime.now() - start_time, \"time\\n\")\n",
    "                        \n",
    "                    else:\n",
    "                        print(\"   Success rate:\", current_success_rate, end=\"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 - W:(1024, 784)\tb:(1024,)\n",
      "Layer 2 - W:(128, 1024)\tb:(128,)\n",
      "Layer 3 - W:(10, 128)\tb:(10,)\n",
      "Total number of parameters: 936330 \n",
      "\n",
      "2019-02-17 15:23:15.028374 - Epoch 1: loss = 0.23640008757004696\n",
      "2019-02-17 15:24:28.177607 - Epoch 2: loss = 0.08659165175077847\n",
      "2019-02-17 15:25:46.750415 - Epoch 3: "
     ]
    }
   ],
   "source": [
    "# best combination of hyperparameters we found\n",
    "batchsize = 4\n",
    "hidden_dims = (1024, 128)\n",
    "activation = \"ReLU\"\n",
    "lr = .1\n",
    "delta = .5\n",
    "\n",
    "np.random.seed(6135)\n",
    "n_epochs = 15\n",
    "\n",
    "neural_net = NN(hidden_dims, n_hidden, mode, datapath, model_path,\n",
    "                batchsize, lr, delta, activation, initialization)\n",
    "neural_net.display_network()\n",
    "\n",
    "# retrain the model to get back the best success rate on validation set\n",
    "neural_net.train(train_data, train_labels, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success rates on validation and test sets\n",
    "\n",
    "print(\"Validation set:\", end='\\t')\n",
    "neural_net.test(valid_data, valid_labels)\n",
    "\n",
    "print(\"Test set:\", end='\\t')\n",
    "neural_net.test(test_data, test_labels)\n",
    "\n",
    "print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finite difference gradient for first 10 weights in first layer\n",
    "Ns, f_grad, t_grad = neural_net.finite_diff(np.expand_dims(train_data[0],axis=0),\n",
    "                                            np.expand_dims(train_labels[0],axis=0))\n",
    "\n",
    "print (Ns)\n",
    "\n",
    "#calculate maximum difference\n",
    "fgd = []\n",
    "for i in range(len(Ns)):\n",
    "    euclidean = np.sum((t_grad-f_grad[i])**2, axis=1)\n",
    "    fgd.append(np.max(euclidean))\n",
    "\n",
    "#plot the maximum difference\n",
    "plt.figure()\n",
    "plt.plot(Ns, np.log(fgd))\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('Log of maximum difference')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
